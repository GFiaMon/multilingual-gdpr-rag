{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3f0f5c1",
   "metadata": {},
   "source": [
    "# ğŸ—„ï¸ GDPR Compliance Agent - Notebook 2: Pinecone Vector Database Setup\n",
    "\n",
    "## ğŸ“‹ Table of Contents\n",
    "1. [Overview](#overview)\n",
    "2. [Setup & Environment](#setup--environment)\n",
    "3. [Load Processed Data](#load-processed-data)\n",
    "4. [Initialize OpenAI Embeddings](#initialize-openai-embeddings)\n",
    "5. [Pinecone Setup](#pinecone-setup)\n",
    "6. [Upload to Vector Database](#upload-to-vector-database)\n",
    "7. [Verification & Testing](#verification--testing)\n",
    "8. [Next Steps](#next-steps)\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ Overview\n",
    "\n",
    "**Goal**: Upload our processed GDPR document chunks to Pinecone vector database and create embeddings using OpenAI.\n",
    "\n",
    "**This Notebook Focus**:\n",
    "- Load chunks processed in Notebook 1\n",
    "- Initialize OpenAI embeddings\n",
    "- Connect to Pinecone vector database\n",
    "- Upload documents with embeddings\n",
    "- Verify the setup works\n",
    "\n",
    "**Key Technologies**:\n",
    "- OpenAI `text-embedding-3-small` for embeddings\n",
    "- Pinecone for vector storage and search\n",
    "- LangChain for orchestration\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4268cdc",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## âš™ï¸ Setup & Environment\n",
    "\n",
    "*Import required libraries and set up environment variables*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4b6064",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/guillermo/venvs/langchain_venv/lib/python3.11/site-packages/langchain_pinecone/__init__.py:3: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  from langchain_pinecone.vectorstores import Pinecone, PineconeVectorStore\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Setup and Imports\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Add project root to Python path\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# LangChain imports\n",
    "from langchain_core.documents import Document\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "# Pinecone imports\n",
    "import pinecone\n",
    "from pinecone import ServerlessSpec\n",
    "\n",
    "# Helper functions\n",
    "from src.embedding_cost_calculator import calculate_embedding_cost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a58abb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”‘ Environment Configuration:\n",
      "   OpenAI API Key: âœ…\n",
      "   Pinecone API Key: âœ…\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Load Environment Variables\n",
    "# Load API keys from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Verify environment variables\n",
    "print(\"ğŸ”‘ Environment Configuration:\")\n",
    "print(f\"   OpenAI API Key: {'âœ…' if os.getenv('OPENAI_API_KEY') else 'âŒ'}\")\n",
    "print(f\"   Pinecone API Key: {'âœ…' if os.getenv('PINECONE_API_KEY') else 'âŒ'}\")\n",
    "# print(f\"   Pinecone Environment: {'âœ…' if os.getenv('PINECONE_ENVIRONMENT') else 'âŒ'}\")\n",
    "\n",
    "# if not all([os.getenv('OPENAI_API_KEY'), os.getenv('PINECONE_API_KEY'), os.getenv('PINECONE_ENVIRONMENT')]):\n",
    "if not all([os.getenv('OPENAI_API_KEY'), os.getenv('PINECONE_API_KEY')]):\n",
    "    print(\"\\nâš ï¸  Missing environment variables!\")\n",
    "    print(\"   Please check your .env file contains:\")\n",
    "    print(\"   - OPENAI_API_KEY\")\n",
    "    print(\"   - PINECONE_API_KEY\")\n",
    "    # print(\"   - PINECONE_ENVIRONMENT\")\n",
    "    print(\"\\n   These are required for this notebook.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d618ac5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“¥ Load Processed Data\n",
    "\n",
    "*Load the chunks and configuration saved from Notebook 1*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f55f3b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Successfully loaded processed data:\n",
      "   - Chunks: 266\n",
      "   - Chunk size: 800\n",
      "   - Overlap: 120\n",
      "   - Estimated tokens: 46,778\n",
      "   - Estimated cost: $0.0009\n",
      "\n",
      "ğŸ“‹ Sample chunk metadata:\n",
      "{'document_type': 'zdh_gdpr_handbook', 'document_name': 'ZDH_LEITFADEN_DATENSCHUTZ_BETRIEBE_HANDWERKER.pdf', 'language': 'german', 'source': '../2_data/raw/ZDH_LEITFADEN_DATENSCHUTZ_BETRIEBE_HANDWERKER.pdf', 'page_number': 1, 'total_pages': 99, 'content_length': 121, 'content_category': 'legal_basis', 'section_type': 'content', 'creationdate': '2020-11-06T11:24:59+01:00', 'author': 'Kasper, Lisa', 'moddate': '2020-11-06T11:24:59+01:00', 'page': 0, 'page_label': '1', 'chunk_id': 1, 'chunk_size': 121, 'total_chunks': 266}\n",
      "\n",
      "ğŸ“ Sample content preview:\n",
      "Leitfaden \n",
      "Datenschutzrecht \n",
      "Was Betriebe zu beachten haben \n",
      " \n",
      " \n",
      "Stand: November 2020 \n",
      " \n",
      "Abteilung Organisation und Recht...\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Load Processed Chunks\n",
    "def load_processed_data():\n",
    "    \"\"\"Load chunks and config from Notebook 1 processing\"\"\"\n",
    "    try:\n",
    "        # Load configuration\n",
    "        with open(\"../2_data/processed/config.pkl\", \"rb\") as f:\n",
    "            config = pickle.load(f)\n",
    "        \n",
    "        # Load chunks\n",
    "        with open(\"../2_data/processed/chunks.pkl\", \"rb\") as f:\n",
    "            serializable_chunks = pickle.load(f)\n",
    "        \n",
    "        # Recreate Document objects\n",
    "        chunks = []\n",
    "        for chunk_data in serializable_chunks:\n",
    "            doc = Document(\n",
    "                page_content=chunk_data['page_content'],\n",
    "                metadata=chunk_data['metadata']\n",
    "            )\n",
    "            chunks.append(doc)\n",
    "        \n",
    "        print(\"âœ… Successfully loaded processed data:\")\n",
    "        print(f\"   - Chunks: {len(chunks)}\")\n",
    "        print(f\"   - Chunk size: {config['chunk_size']}\")\n",
    "        print(f\"   - Overlap: {config['chunk_overlap']}\")\n",
    "        print(f\"   - Estimated tokens: {config['total_tokens']:,}\")\n",
    "        print(f\"   - Estimated cost: ${config['estimated_cost']:.4f}\")\n",
    "        \n",
    "        return chunks, config\n",
    "        \n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"âŒ Error: {e}\")\n",
    "        print(\"ğŸ’¡ Please run Notebook 1 first to process the PDF\")\n",
    "        return [], {}\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Unexpected error: {e}\")\n",
    "        return [], {}\n",
    "\n",
    "# Load the data\n",
    "chunks, config = load_processed_data()\n",
    "\n",
    "if not chunks:\n",
    "    print(\"âŒ Cannot proceed without processed chunks.\")\n",
    "else:\n",
    "    # Show sample chunk\n",
    "    print(f\"\\nğŸ“‹ Sample chunk metadata:\")\n",
    "    print(chunks[0].metadata)\n",
    "    print(f\"\\nğŸ“ Sample content preview:\")\n",
    "    print(chunks[0].page_content[:200] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6576b37",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## ğŸ¤– Initialize OpenAI Embeddings\n",
    "\n",
    "*Set up the embedding model that will convert text to vectors*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c081f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… OpenAI Embeddings initialized successfully!\n",
      "   Model: text-embedding-3-small\n",
      "   Dimension: 1536 (for text-embedding-3-small)\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Initialize OpenAI Embeddings\n",
    "def initialize_embeddings():\n",
    "    \"\"\"Initialize OpenAI embeddings without test query\"\"\"\n",
    "    try:\n",
    "        embeddings = OpenAIEmbeddings(\n",
    "            model=\"text-embedding-3-small\",\n",
    "            openai_api_key=os.getenv('OPENAI_API_KEY')\n",
    "        )\n",
    "        \n",
    "        print(\"âœ… OpenAI Embeddings initialized successfully!\")\n",
    "        print(f\"   Model: text-embedding-3-small\")\n",
    "        print(f\"   Dimension: 1536 (for text-embedding-3-small)\")\n",
    "        \n",
    "        return embeddings\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error initializing OpenAI embeddings: {e}\")\n",
    "        print(\"ğŸ’¡ Check your OPENAI_API_KEY in .env file\")\n",
    "        return None\n",
    "\n",
    "# Initialize embeddings\n",
    "embeddings = initialize_embeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d906f2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ—ƒï¸ Pinecone Setup\n",
    "\n",
    "*Initialize connection to Pinecone vector database*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6e00cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Pinecone initialized for PineconeVectorStore!\n",
      "ğŸ“‹ Existing indexes: ['extractive-question-answering', 'gdpr-compliance-openai', 'langchain-retrieval-agent', 'abstractive-qa-history', 'gdpr-compliance']\n",
      "âœ… Using existing index: gdpr-compliance-openai\n",
      "ğŸ“Š Index statistics:\n",
      "   - Total vectors: 0\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Pinecone Setup (Optimized for PineconeVectorStore)\n",
    "def initialize_pinecone_for_vectorstore(index_name=\"gdpr-compliance-openai\"):\n",
    "    \"\"\"Initialize Pinecone specifically for PineconeVectorStore compatibility\"\"\"\n",
    "    try:\n",
    "        from pinecone import Pinecone, ServerlessSpec\n",
    "        \n",
    "        pc = Pinecone(api_key=os.getenv('PINECONE_API_KEY'))\n",
    "        \n",
    "        print(\"âœ… Pinecone initialized for PineconeVectorStore!\")\n",
    "        \n",
    "        existing_indexes = pc.list_indexes().names()\n",
    "        print(f\"ğŸ“‹ Existing indexes: {existing_indexes}\")\n",
    "        \n",
    "        if index_name not in existing_indexes:\n",
    "            print(f\"ğŸ“¦ Creating new index: {index_name}\")\n",
    "            \n",
    "            pc.create_index(\n",
    "                name=index_name,\n",
    "                dimension=1536,\n",
    "                metric='cosine',\n",
    "                spec=ServerlessSpec(\n",
    "                    cloud='aws',\n",
    "                    region='us-east-1'\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            print(\"â³ Waiting for index to initialize...\")\n",
    "            while not pc.describe_index(index_name).status['ready']:\n",
    "                time.sleep(1)\n",
    "            \n",
    "            print(\"âœ… Index created and ready!\")\n",
    "        else:\n",
    "            print(f\"âœ… Using existing index: {index_name}\")\n",
    "        \n",
    "        # Return both pc and index for flexibility\n",
    "        index = pc.Index(index_name)\n",
    "        time.sleep(1)\n",
    "        \n",
    "        stats = index.describe_index_stats()\n",
    "        print(f\"ğŸ“Š Index statistics:\")\n",
    "        print(f\"   - Total vectors: {stats['total_vector_count']}\")\n",
    "        \n",
    "        return pc, index\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error initializing Pinecone: {e}\")\n",
    "        return None, None\n",
    "\n",
    "# Initialize Pinecone\n",
    "pc, index = initialize_pinecone_for_vectorstore()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40681d1",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸš€ Upload to Vector Database\n",
    "\n",
    "*Upload document chunks to Pinecone with embeddings*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f347b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ Creating Pinecone vector store...\n",
      "âœ… Successfully loaded 266 documents into Pinecone\n",
      "ğŸ“Š Stats: 266 chunks, ~170805 characters\n"
     ]
    }
   ],
   "source": [
    "# # Cell 6: Current Vector Store Setup\n",
    "\n",
    "def create_pinecone_vectorstore_simple(chunks, index_name=\"gdpr-compliance-openai\"):\n",
    "    \"\"\"Simple version without cost calculation\"\"\"\n",
    "    \n",
    "    embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "    \n",
    "    print(\"ğŸ”„ Creating Pinecone vector store...\")\n",
    "    vectorstore = PineconeVectorStore.from_documents(\n",
    "        documents=chunks,\n",
    "        embedding=embeddings,\n",
    "        index_name=index_name\n",
    "    )\n",
    "    \n",
    "    print(f\"âœ… Successfully loaded {len(chunks)} documents into Pinecone\")\n",
    "    \n",
    "    # Optional: Show basic stats\n",
    "    total_chars = sum(len(chunk.page_content) for chunk in chunks)\n",
    "    print(f\"ğŸ“Š Stats: {len(chunks)} chunks, ~{total_chars} characters\")\n",
    "    \n",
    "    return vectorstore\n",
    "\n",
    "# Use the simple version\n",
    "vectorstore = create_pinecone_vectorstore_simple(chunks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce16792",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## âœ… Verification & Testing\n",
    "\n",
    "*Verify that the upload worked and test search functionality*. (No Tokens used, only search similarity?)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "704acafc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§ª Testing Vector Store Retrieval...\n",
      "\n",
      "ğŸ” Query: 'Was ist die Datenschutzrichtlinie?'\n",
      "   Found 2 relevant chunks:\n",
      "   1. Leitfaden \n",
      "Datenschutzrecht \n",
      "Was Betriebe zu beachten haben \n",
      " \n",
      " \n",
      "Stand: November 2020 \n",
      " \n",
      "Abteilung Organisation und Recht...\n",
      "   2. 3. Formelle Pflichten von Betrieben â€“ Ein Ãœberblick  \n",
      " \n",
      "Welchen Zweck verfolgen die Pflichten?  \n",
      " \n",
      "Das Datenschutzrecht rÃ¤umt Personen, deren Daten vo...\n",
      "   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "ğŸ” Query: 'Wie sollen Kundendaten behandelt werden?'\n",
      "   Found 2 relevant chunks:\n",
      "   1. Kunde \n",
      " \n",
      " \n",
      "Familienname \n",
      " \n",
      " \n",
      "Vorname \n",
      " \n",
      " \n",
      "Geburtsname \n",
      " \n",
      " \n",
      "Geschlecht \n",
      " \n",
      " \n",
      "Geburtsdatum \n",
      " \n",
      " \n",
      "StaatsangehÃ¶rigkeit \n",
      " \n",
      " \n",
      "StraÃŸe \n",
      " \n",
      " \n",
      "PLZ \n",
      " \n",
      " \n",
      "Wohnort \n",
      " \n",
      "...\n",
      "   2. Gesetz vorgesehene Informationen zu erteilen. Dies sind im Einzelnen: \n",
      "  \n",
      "â—¼ Alle Ã¼ber den Betroffenen gespeicherten Daten (z.B. Name, Anschrift, E -Ma...\n",
      "   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "ğŸ” Query: 'Was sind die GDPR-Anforderungen?'\n",
      "   Found 2 relevant chunks:\n",
      "   1. Rechtliche Grundlagen  \n",
      "Artikel 5 DSGVO  \n",
      "(1) Personenbezogene Daten mÃ¼ssen  \n",
      " \n",
      "a) auf rechtmÃ¤ÃŸige Weise, nach Treu und Glauben und in einer fÃ¼r die b...\n",
      "   2. (DSGVO) geregelt. Die Vorschriften werden durch die Â§Â§ 32 bis 37 des Bundesdatenschutz-\n",
      "gesetzes (BDSG) ergÃ¤nzt. \n",
      " \n",
      "Betriebe, die Daten nutzen, werden...\n",
      "   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "ğŸ” Query: 'Wie geht man mit personenbezogenen Daten um?'\n",
      "   Found 2 relevant chunks:\n",
      "   1. 4. Informationspflichten bei Erhebung personenbezogener \n",
      "Daten \n",
      " \n",
      "Transparenz durch Informationen \n",
      " \n",
      "Personen, deren Daten von einem anderen verarbeit...\n",
      "   2. den, wie bei der Erhebung beim Betroffenen selbst.  \n",
      " \n",
      "ZusÃ¤tzlich sind dem Betroffenen zwei weitere Informationen zu erteilen: \n",
      " \n",
      "â—¼ Welche Kategorien ...\n",
      "   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "ğŸ” Query: 'Was muss bei Datenverarbeitung beachtet werden?'\n",
      "   Found 2 relevant chunks:\n",
      "   1. Technische und organisatorische MaÃŸnahmen \n",
      "  \n",
      "Betriebe sind verpflichtet, MaÃŸnahmen auf dem Stand der Technik zu ergreifen, um den Ri-\n",
      "siken zu begegn...\n",
      "   2. AbschlieÃŸen des Serverraums). \n",
      " \n",
      "â—¼ IntegritÃ¤t der Datenverarbeitung (u.a. Eingabekontrolle/ Verarbeitungskontrol-\n",
      "le) \n",
      "MaÃŸnahmen, die gewÃ¤hrleisten, d...\n",
      "   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "ğŸ” Query: 'Welche Rechte haben Kunden bezÃ¼glich ihrer Daten?'\n",
      "   Found 2 relevant chunks:\n",
      "   1. Sie haben das Recht, der Verwendung Ihrer Daten zum Zweck der Datenweiterleitung an den \n",
      "Nachfolgeinhaber jederzeit zu widersprechen. Zudem sind Sie b...\n",
      "   2. Kunden steht aber ein Widerspruchsrecht zu. Deshalb muss der alte Betriebsinhaber die \n",
      "Kunden im Vorlauf zum Betriebsverkauf Ã¼ber die beabsichtigte Da...\n",
      "   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "âœ… Vector store test completed!\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Test Vector Store and Build RAG Chain\n",
    "print(\"ğŸ§ª Testing Vector Store Retrieval...\")\n",
    "\n",
    "# Test with some sample queries\n",
    "# Test with German queries that match your data protection content\n",
    "test_queries = [\n",
    "    \"Was ist die Datenschutzrichtlinie?\",\n",
    "    \"Wie sollen Kundendaten behandelt werden?\",\n",
    "    \"Was sind die GDPR-Anforderungen?\",\n",
    "    \"Wie geht man mit personenbezogenen Daten um?\",\n",
    "    \"Was muss bei Datenverarbeitung beachtet werden?\",\n",
    "    \"Welche Rechte haben Kunden bezÃ¼glich ihrer Daten?\"\n",
    "]\n",
    "\n",
    "\n",
    "for query in test_queries:\n",
    "    print(f\"\\nğŸ” Query: '{query}'\")\n",
    "    results = vectorstore.similarity_search(query, k=2)\n",
    "    \n",
    "    print(f\"   Found {len(results)} relevant chunks:\")\n",
    "    for i, doc in enumerate(results):\n",
    "        print(f\"   {i+1}. {doc.page_content[:150]}...\")\n",
    "    print(\"   \" + \"â”€\" * 50)\n",
    "\n",
    "print(\"\\nâœ… Vector store test completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a664b4",
   "metadata": {},
   "source": [
    "------\n",
    "------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LangChain",
   "language": "python",
   "name": "langchain_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
