{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3f0f5c1",
   "metadata": {},
   "source": [
    "# üóÑÔ∏è GDPR Compliance Agent - Notebook 2: Pinecone Vector Database Setup\n",
    "\n",
    "## üìã Table of Contents\n",
    "1. [Overview](#overview)\n",
    "2. [Setup & Environment](#setup--environment)\n",
    "3. [Load Processed Data](#load-processed-data)\n",
    "4. [Initialize OpenAI Embeddings](#initialize-openai-embeddings)\n",
    "5. [Pinecone Setup](#pinecone-setup)\n",
    "6. [Upload to Vector Database](#upload-to-vector-database)\n",
    "7. [Verification & Testing](#verification--testing)\n",
    "8. [Next Steps](#next-steps)\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Overview\n",
    "\n",
    "**Goal**: Upload our processed GDPR document chunks to Pinecone vector database and create embeddings using OpenAI.\n",
    "\n",
    "**This Notebook Focus**:\n",
    "- Load chunks processed in Notebook 1\n",
    "- Initialize OpenAI embeddings\n",
    "- Connect to Pinecone vector database\n",
    "- Upload documents with embeddings\n",
    "- Verify the setup works\n",
    "\n",
    "**Key Technologies**:\n",
    "- OpenAI `text-embedding-3-small` for embeddings\n",
    "- Pinecone for vector storage and search\n",
    "- LangChain for orchestration\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4268cdc",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚öôÔ∏è Setup & Environment\n",
    "\n",
    "*Import required libraries and set up environment variables*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b4b6064",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/guillermo/venvs/langchain_venv/lib/python3.11/site-packages/langchain_pinecone/__init__.py:3: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  from langchain_pinecone.vectorstores import Pinecone, PineconeVectorStore\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Setup and Imports\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Add project root to Python path\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# LangChain imports\n",
    "from langchain_core.documents import Document\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "# Pinecone imports\n",
    "import pinecone\n",
    "from pinecone import ServerlessSpec\n",
    "\n",
    "# Helper functions\n",
    "from src.embedding_cost_calculator import calculate_embedding_cost\n",
    "\n",
    "# print(\"‚úÖ All imports completed successfully!\")\n",
    "# print(\"üîë Environment Check:\")\n",
    "# print(f\"   OpenAI API Key: {'‚úÖ' if os.getenv('OPENAI_API_KEY') else '‚ùå'}\")\n",
    "# print(f\"   Pinecone API Key: {'‚úÖ' if os.getenv('PINECONE_API_KEY') else '‚ùå'}\")\n",
    "\n",
    "# if not all([os.getenv('OPENAI_API_KEY'), os.getenv('PINECONE_API_KEY')]):\n",
    "#     print(\"\\n‚ùå Missing API keys. Please check your .env file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "293e2148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Cell 1: Setup and Imports. (OlD)\n",
    "# import os \n",
    "# import sys\n",
    "# import pickle\n",
    "# from dotenv import load_dotenv\n",
    "\n",
    "# # Add project root to Python path\n",
    "# sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "# # LangChain imports\n",
    "# from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "# from langchain.vectorstores import Pinecone\n",
    "# from langchain.schema import Document\n",
    "# from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "# # Pinecone import\n",
    "# from pinecone import Pinecone\n",
    "# from pinecone import ServerlessSpec\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Import time for the wait functionality\n",
    "# import time\n",
    "\n",
    "# # Helper functions\n",
    "# from src.embedding_cost_calculator import calculate_embedding_cost\n",
    "\n",
    "# print(\"‚úÖ Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a58abb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîë Environment Configuration:\n",
      "   OpenAI API Key: ‚úÖ\n",
      "   Pinecone API Key: ‚úÖ\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Load Environment Variables\n",
    "# Load API keys from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Verify environment variables\n",
    "print(\"üîë Environment Configuration:\")\n",
    "print(f\"   OpenAI API Key: {'‚úÖ' if os.getenv('OPENAI_API_KEY') else '‚ùå'}\")\n",
    "print(f\"   Pinecone API Key: {'‚úÖ' if os.getenv('PINECONE_API_KEY') else '‚ùå'}\")\n",
    "# print(f\"   Pinecone Environment: {'‚úÖ' if os.getenv('PINECONE_ENVIRONMENT') else '‚ùå'}\")\n",
    "\n",
    "# if not all([os.getenv('OPENAI_API_KEY'), os.getenv('PINECONE_API_KEY'), os.getenv('PINECONE_ENVIRONMENT')]):\n",
    "if not all([os.getenv('OPENAI_API_KEY'), os.getenv('PINECONE_API_KEY')]):\n",
    "    print(\"\\n‚ö†Ô∏è  Missing environment variables!\")\n",
    "    print(\"   Please check your .env file contains:\")\n",
    "    print(\"   - OPENAI_API_KEY\")\n",
    "    print(\"   - PINECONE_API_KEY\")\n",
    "    # print(\"   - PINECONE_ENVIRONMENT\")\n",
    "    print(\"\\n   These are required for this notebook.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d618ac5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üì• Load Processed Data\n",
    "\n",
    "*Load the chunks and configuration saved from Notebook 1*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f55f3b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Successfully loaded processed data:\n",
      "   - Chunks: 266\n",
      "   - Chunk size: 800\n",
      "   - Overlap: 120\n",
      "   - Estimated tokens: 46,778\n",
      "   - Estimated cost: $0.0009\n",
      "\n",
      "üìã Sample chunk metadata:\n",
      "{'document_type': 'zdh_gdpr_handbook', 'document_name': 'ZDH_LEITFADEN_DATENSCHUTZ_BETRIEBE_HANDWERKER.pdf', 'language': 'german', 'source': '../2_data/raw/ZDH_LEITFADEN_DATENSCHUTZ_BETRIEBE_HANDWERKER.pdf', 'page_number': 1, 'total_pages': 99, 'content_length': 121, 'content_category': 'legal_basis', 'section_type': 'content', 'creationdate': '2020-11-06T11:24:59+01:00', 'author': 'Kasper, Lisa', 'moddate': '2020-11-06T11:24:59+01:00', 'page': 0, 'page_label': '1', 'chunk_id': 1, 'chunk_size': 121, 'total_chunks': 266}\n",
      "\n",
      "üìù Sample content preview:\n",
      "Leitfaden \n",
      "Datenschutzrecht \n",
      "Was Betriebe zu beachten haben \n",
      " \n",
      " \n",
      "Stand: November 2020 \n",
      " \n",
      "Abteilung Organisation und Recht...\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Load Processed Chunks\n",
    "def load_processed_data():\n",
    "    \"\"\"Load chunks and config from Notebook 1 processing\"\"\"\n",
    "    try:\n",
    "        # Load configuration\n",
    "        with open(\"../2_data/processed/config.pkl\", \"rb\") as f:\n",
    "            config = pickle.load(f)\n",
    "        \n",
    "        # Load chunks\n",
    "        with open(\"../2_data/processed/chunks.pkl\", \"rb\") as f:\n",
    "            serializable_chunks = pickle.load(f)\n",
    "        \n",
    "        # Recreate Document objects\n",
    "        chunks = []\n",
    "        for chunk_data in serializable_chunks:\n",
    "            doc = Document(\n",
    "                page_content=chunk_data['page_content'],\n",
    "                metadata=chunk_data['metadata']\n",
    "            )\n",
    "            chunks.append(doc)\n",
    "        \n",
    "        print(\"‚úÖ Successfully loaded processed data:\")\n",
    "        print(f\"   - Chunks: {len(chunks)}\")\n",
    "        print(f\"   - Chunk size: {config['chunk_size']}\")\n",
    "        print(f\"   - Overlap: {config['chunk_overlap']}\")\n",
    "        print(f\"   - Estimated tokens: {config['total_tokens']:,}\")\n",
    "        print(f\"   - Estimated cost: ${config['estimated_cost']:.4f}\")\n",
    "        \n",
    "        return chunks, config\n",
    "        \n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "        print(\"üí° Please run Notebook 1 first to process the PDF\")\n",
    "        return [], {}\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Unexpected error: {e}\")\n",
    "        return [], {}\n",
    "\n",
    "# Load the data\n",
    "chunks, config = load_processed_data()\n",
    "\n",
    "if not chunks:\n",
    "    print(\"‚ùå Cannot proceed without processed chunks.\")\n",
    "else:\n",
    "    # Show sample chunk\n",
    "    print(f\"\\nüìã Sample chunk metadata:\")\n",
    "    print(chunks[0].metadata)\n",
    "    print(f\"\\nüìù Sample content preview:\")\n",
    "    print(chunks[0].page_content[:200] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6576b37",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## ü§ñ Initialize OpenAI Embeddings\n",
    "\n",
    "*Set up the embedding model that will convert text to vectors*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c081f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ OpenAI Embeddings initialized successfully!\n",
      "   Model: text-embedding-3-small\n",
      "   Dimension: 1536 (for text-embedding-3-small)\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Initialize OpenAI Embeddings\n",
    "def initialize_embeddings():\n",
    "    \"\"\"Initialize OpenAI embeddings without test query\"\"\"\n",
    "    try:\n",
    "        embeddings = OpenAIEmbeddings(\n",
    "            model=\"text-embedding-3-small\",\n",
    "            openai_api_key=os.getenv('OPENAI_API_KEY')\n",
    "        )\n",
    "        \n",
    "        print(\"‚úÖ OpenAI Embeddings initialized successfully!\")\n",
    "        print(f\"   Model: text-embedding-3-small\")\n",
    "        print(f\"   Dimension: 1536 (for text-embedding-3-small)\")\n",
    "        \n",
    "        return embeddings\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error initializing OpenAI embeddings: {e}\")\n",
    "        print(\"üí° Check your OPENAI_API_KEY in .env file\")\n",
    "        return None\n",
    "\n",
    "# Initialize embeddings\n",
    "embeddings = initialize_embeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d906f2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üóÉÔ∏è Pinecone Setup\n",
    "\n",
    "*Initialize connection to Pinecone vector database*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6e00cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Pinecone initialized for PineconeVectorStore!\n",
      "üìã Existing indexes: ['extractive-question-answering', 'gdpr-compliance-openai', 'langchain-retrieval-agent', 'abstractive-qa-history', 'gdpr-compliance']\n",
      "‚úÖ Using existing index: gdpr-compliance-openai\n",
      "üìä Index statistics:\n",
      "   - Total vectors: 0\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Pinecone Setup (Optimized for PineconeVectorStore)\n",
    "def initialize_pinecone_for_vectorstore(index_name=\"gdpr-compliance-openai\"):\n",
    "    \"\"\"Initialize Pinecone specifically for PineconeVectorStore compatibility\"\"\"\n",
    "    try:\n",
    "        from pinecone import Pinecone, ServerlessSpec\n",
    "        \n",
    "        pc = Pinecone(api_key=os.getenv('PINECONE_API_KEY'))\n",
    "        \n",
    "        print(\"‚úÖ Pinecone initialized for PineconeVectorStore!\")\n",
    "        \n",
    "        existing_indexes = pc.list_indexes().names()\n",
    "        print(f\"üìã Existing indexes: {existing_indexes}\")\n",
    "        \n",
    "        if index_name not in existing_indexes:\n",
    "            print(f\"üì¶ Creating new index: {index_name}\")\n",
    "            \n",
    "            pc.create_index(\n",
    "                name=index_name,\n",
    "                dimension=1536,\n",
    "                metric='cosine',\n",
    "                spec=ServerlessSpec(\n",
    "                    cloud='aws',\n",
    "                    region='us-east-1'\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            print(\"‚è≥ Waiting for index to initialize...\")\n",
    "            while not pc.describe_index(index_name).status['ready']:\n",
    "                time.sleep(1)\n",
    "            \n",
    "            print(\"‚úÖ Index created and ready!\")\n",
    "        else:\n",
    "            print(f\"‚úÖ Using existing index: {index_name}\")\n",
    "        \n",
    "        # Return both pc and index for flexibility\n",
    "        index = pc.Index(index_name)\n",
    "        time.sleep(1)\n",
    "        \n",
    "        stats = index.describe_index_stats()\n",
    "        print(f\"üìä Index statistics:\")\n",
    "        print(f\"   - Total vectors: {stats['total_vector_count']}\")\n",
    "        \n",
    "        return pc, index\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error initializing Pinecone: {e}\")\n",
    "        return None, None\n",
    "\n",
    "# Initialize Pinecone\n",
    "pc, index = initialize_pinecone_for_vectorstore()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40681d1",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "## üöÄ Upload to Vector Database\n",
    "\n",
    "*Upload document chunks to Pinecone with embeddings*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f347b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Creating Pinecone vector store...\n",
      "‚úÖ Successfully loaded 266 documents into Pinecone\n",
      "üìä Stats: 266 chunks, ~170805 characters\n"
     ]
    }
   ],
   "source": [
    "# # Cell 6: Current Vector Store Setup\n",
    "\n",
    "def create_pinecone_vectorstore_simple(chunks, index_name=\"gdpr-compliance-openai\"):\n",
    "    \"\"\"Simple version without cost calculation\"\"\"\n",
    "    \n",
    "    embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "    \n",
    "    print(\"üîÑ Creating Pinecone vector store...\")\n",
    "    vectorstore = PineconeVectorStore.from_documents(\n",
    "        documents=chunks,\n",
    "        embedding=embeddings,\n",
    "        index_name=index_name\n",
    "    )\n",
    "    \n",
    "    print(f\"‚úÖ Successfully loaded {len(chunks)} documents into Pinecone\")\n",
    "    \n",
    "    # Optional: Show basic stats\n",
    "    total_chars = sum(len(chunk.page_content) for chunk in chunks)\n",
    "    print(f\"üìä Stats: {len(chunks)} chunks, ~{total_chars} characters\")\n",
    "    \n",
    "    return vectorstore\n",
    "\n",
    "# Use the simple version\n",
    "vectorstore = create_pinecone_vectorstore_simple(chunks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c96d1e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2ce16792",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Verification & Testing\n",
    "\n",
    "*Verify that the upload worked and test search functionality*. (No Tokens used, only search similarity?)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "704acafc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Testing Vector Store Retrieval...\n",
      "\n",
      "üîç Query: 'Was ist die Datenschutzrichtlinie?'\n",
      "   Found 2 relevant chunks:\n",
      "   1. Leitfaden \n",
      "Datenschutzrecht \n",
      "Was Betriebe zu beachten haben \n",
      " \n",
      " \n",
      "Stand: November 2020 \n",
      " \n",
      "Abteilung Organisation und Recht...\n",
      "   2. 3. Formelle Pflichten von Betrieben ‚Äì Ein √úberblick  \n",
      " \n",
      "Welchen Zweck verfolgen die Pflichten?  \n",
      " \n",
      "Das Datenschutzrecht r√§umt Personen, deren Daten vo...\n",
      "   ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "üîç Query: 'Wie sollen Kundendaten behandelt werden?'\n",
      "   Found 2 relevant chunks:\n",
      "   1. Kunde \n",
      " \n",
      " \n",
      "Familienname \n",
      " \n",
      " \n",
      "Vorname \n",
      " \n",
      " \n",
      "Geburtsname \n",
      " \n",
      " \n",
      "Geschlecht \n",
      " \n",
      " \n",
      "Geburtsdatum \n",
      " \n",
      " \n",
      "Staatsangeh√∂rigkeit \n",
      " \n",
      " \n",
      "Stra√üe \n",
      " \n",
      " \n",
      "PLZ \n",
      " \n",
      " \n",
      "Wohnort \n",
      " \n",
      "...\n",
      "   2. Gesetz vorgesehene Informationen zu erteilen. Dies sind im Einzelnen: \n",
      "  \n",
      "‚óº Alle √ºber den Betroffenen gespeicherten Daten (z.B. Name, Anschrift, E -Ma...\n",
      "   ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "üîç Query: 'Was sind die GDPR-Anforderungen?'\n",
      "   Found 2 relevant chunks:\n",
      "   1. Rechtliche Grundlagen  \n",
      "Artikel 5 DSGVO  \n",
      "(1) Personenbezogene Daten m√ºssen  \n",
      " \n",
      "a) auf rechtm√§√üige Weise, nach Treu und Glauben und in einer f√ºr die b...\n",
      "   2. (DSGVO) geregelt. Die Vorschriften werden durch die ¬ß¬ß 32 bis 37 des Bundesdatenschutz-\n",
      "gesetzes (BDSG) erg√§nzt. \n",
      " \n",
      "Betriebe, die Daten nutzen, werden...\n",
      "   ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "üîç Query: 'Wie geht man mit personenbezogenen Daten um?'\n",
      "   Found 2 relevant chunks:\n",
      "   1. 4. Informationspflichten bei Erhebung personenbezogener \n",
      "Daten \n",
      " \n",
      "Transparenz durch Informationen \n",
      " \n",
      "Personen, deren Daten von einem anderen verarbeit...\n",
      "   2. den, wie bei der Erhebung beim Betroffenen selbst.  \n",
      " \n",
      "Zus√§tzlich sind dem Betroffenen zwei weitere Informationen zu erteilen: \n",
      " \n",
      "‚óº Welche Kategorien ...\n",
      "   ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "üîç Query: 'Was muss bei Datenverarbeitung beachtet werden?'\n",
      "   Found 2 relevant chunks:\n",
      "   1. Technische und organisatorische Ma√ünahmen \n",
      "  \n",
      "Betriebe sind verpflichtet, Ma√ünahmen auf dem Stand der Technik zu ergreifen, um den Ri-\n",
      "siken zu begegn...\n",
      "   2. Abschlie√üen des Serverraums). \n",
      " \n",
      "‚óº Integrit√§t der Datenverarbeitung (u.a. Eingabekontrolle/ Verarbeitungskontrol-\n",
      "le) \n",
      "Ma√ünahmen, die gew√§hrleisten, d...\n",
      "   ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "üîç Query: 'Welche Rechte haben Kunden bez√ºglich ihrer Daten?'\n",
      "   Found 2 relevant chunks:\n",
      "   1. Sie haben das Recht, der Verwendung Ihrer Daten zum Zweck der Datenweiterleitung an den \n",
      "Nachfolgeinhaber jederzeit zu widersprechen. Zudem sind Sie b...\n",
      "   2. Kunden steht aber ein Widerspruchsrecht zu. Deshalb muss der alte Betriebsinhaber die \n",
      "Kunden im Vorlauf zum Betriebsverkauf √ºber die beabsichtigte Da...\n",
      "   ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "‚úÖ Vector store test completed!\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Test Vector Store and Build RAG Chain\n",
    "print(\"üß™ Testing Vector Store Retrieval...\")\n",
    "\n",
    "# Test with some sample queries\n",
    "# Test with German queries that match your data protection content\n",
    "test_queries = [\n",
    "    \"Was ist die Datenschutzrichtlinie?\",\n",
    "    \"Wie sollen Kundendaten behandelt werden?\",\n",
    "    \"Was sind die GDPR-Anforderungen?\",\n",
    "    \"Wie geht man mit personenbezogenen Daten um?\",\n",
    "    \"Was muss bei Datenverarbeitung beachtet werden?\",\n",
    "    \"Welche Rechte haben Kunden bez√ºglich ihrer Daten?\"\n",
    "]\n",
    "\n",
    "\n",
    "for query in test_queries:\n",
    "    print(f\"\\nüîç Query: '{query}'\")\n",
    "    results = vectorstore.similarity_search(query, k=2)\n",
    "    \n",
    "    print(f\"   Found {len(results)} relevant chunks:\")\n",
    "    for i, doc in enumerate(results):\n",
    "        print(f\"   {i+1}. {doc.page_content[:150]}...\")\n",
    "    print(\"   \" + \"‚îÄ\" * 50)\n",
    "\n",
    "print(\"\\n‚úÖ Vector store test completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc95591",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4affe3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cell 7: Verify Upload and Test Search\n",
    "def verify_pinecone_upload():\n",
    "    \"\"\"Verify the upload was successful and test search functionality\"\"\"\n",
    "    try:\n",
    "        # Get updated index stats\n",
    "        index = pinecone.Index(\"gdpr-compliance\")\n",
    "        stats = index.describe_index_stats()\n",
    "        \n",
    "        print(\"üìä Final Vector Database Status:\")\n",
    "        print(f\"   Total vectors: {stats['total_vector_count']}\")\n",
    "        print(f\"   Dimension: {stats['dimension']}\")\n",
    "        \n",
    "        expected_vectors = len(chunks)\n",
    "        actual_vectors = stats['total_vector_count']\n",
    "        \n",
    "        if actual_vectors >= expected_vectors:\n",
    "            print(f\"   ‚úÖ Upload successful: {actual_vectors} vectors stored\")\n",
    "        else:\n",
    "            print(f\"   ‚ö†Ô∏è  Partial upload: {actual_vectors}/{expected_vectors} vectors\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error verifying upload: {e}\")\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3345cf5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test_search_functionality(vectorstore):\n",
    "    \"\"\"Test that search is working with sample queries\"\"\"\n",
    "    if not vectorstore:\n",
    "        print(\"‚ùå No vectorstore available for testing\")\n",
    "        return\n",
    "    \n",
    "    print(\"\\nüîç Testing Search Functionality:\")\n",
    "    \n",
    "    # Test queries in German (matching our document language)\n",
    "    test_queries = [\n",
    "        \"Datenschutz Grundverordnung\",\n",
    "        \"Kundendaten Aufbewahrung\", \n",
    "        \"Mitarbeiter Daten\",\n",
    "        \"Einwilligung Marketing\",\n",
    "        \"Datenpanne Meldefrist\"\n",
    "    ]\n",
    "    \n",
    "    for query in test_queries:\n",
    "        print(f\"\\n   Query: '{query}'\")\n",
    "        \n",
    "        try:\n",
    "            # Search for similar documents\n",
    "            results = vectorstore.similarity_search(query, k=2)\n",
    "            \n",
    "            print(f\"      Found {len(results)} relevant documents:\")\n",
    "            \n",
    "            for i, result in enumerate(results):\n",
    "                category = result.metadata.get('content_category', 'N/A')\n",
    "                page = result.metadata.get('page_number', 'N/A')\n",
    "                print(f\"      {i+1}. Category: {category}, Page: {page}\")\n",
    "                print(f\"         Preview: {result.page_content[:80]}...\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"      ‚ùå Search error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed9a9610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Error verifying upload: module 'pinecone' has no attribute 'Index'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Run verification and tests\n",
    "if vectorstore:\n",
    "    verification_success = verify_pinecone_upload()\n",
    "    if verification_success:\n",
    "        test_search_functionality(vectorstore)\n",
    "else:\n",
    "    print(\"‚ùå Cannot verify - no vectorstore created\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2218ea7",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## üíæ Save Vector Store Reference\n",
    "\n",
    "*Save the vector store reference for use in Notebook 3*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85cb650f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Save Configuration for Next Notebook\n",
    "def save_vectorstore_config(vectorstore, chunks):\n",
    "    \"\"\"Save configuration for the next notebook\"\"\"\n",
    "    try:\n",
    "        config = {\n",
    "            \"index_name\": \"gdpr-compliance\",\n",
    "            \"embedding_model\": \"text-embedding-3-small\", \n",
    "            \"total_chunks\": len(chunks),\n",
    "            \"vectorstore_ready\": vectorstore is not None\n",
    "        }\n",
    "        \n",
    "        with open(\"../data/processed/vectorstore_config.pkl\", \"wb\") as f:\n",
    "            pickle.dump(config, f)\n",
    "        \n",
    "        print(\"üíæ Saved vectorstore configuration for Notebook 3\")\n",
    "        print(f\"   File: ../data/processed/vectorstore_config.pkl\")\n",
    "        \n",
    "        return config\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error saving configuration: {e}\")\n",
    "        return {}\n",
    "\n",
    "# Save configuration\n",
    "if vectorstore:\n",
    "    final_config = save_vectorstore_config(vectorstore, chunks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5565698b",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## üéâ Next Steps\n",
    "\n",
    "*Summary and preparation for Notebook 3*\n",
    "\n",
    "```python\n",
    "# Cell 9: Completion Summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üéâ NOTEBOOK 2 COMPLETE!\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if vectorstore:\n",
    "    print(\"‚úÖ SUCCESS: Vector database is ready!\")\n",
    "    print(f\"   - {len(chunks)} document chunks uploaded\")\n",
    "    print(f\"   - Embeddings created with text-embedding-3-small\")\n",
    "    print(f\"   - Pinecone index: gdpr-compliance\")\n",
    "    print(f\"   - Search functionality verified\")\n",
    "    \n",
    "    print(\"\\n‚û°Ô∏è  NEXT: Notebook 3 - RAG Agent\")\n",
    "    print(\"   - Create question-answering system\")\n",
    "    print(\"   - Connect GPT model to vector database\")\n",
    "    print(\"   - Build complete RAG pipeline\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå INCOMPLETE: Issues with vector database setup\")\n",
    "    print(\"   Please check:\")\n",
    "    print(\"   - API keys in .env file\")\n",
    "    print(\"   - Pinecone index exists\")\n",
    "    print(\"   - Internet connection for API calls\")\n",
    "\n",
    "print(\"\\nüìÅ Files created for next notebook:\")\n",
    "print(\"   - ../data/processed/vectorstore_config.pkl\")\n",
    "print(\"=\"*60)\n",
    "```\n",
    "\n",
    "## üöÄ Ready for Notebook 3!\n",
    "\n",
    "Your vector database is now populated and ready for the RAG agent in Notebook 3!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a664b4",
   "metadata": {},
   "source": [
    "------\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37356a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "asd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1acea9",
   "metadata": {},
   "source": [
    "\n",
    "-----\n",
    "-----\n",
    "# Draft"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8eb804",
   "metadata": {},
   "source": [
    "## üî¢ Embeddings Setup\n",
    "\n",
    "*Initialize the embedding model that converts text to numbers*\n",
    "\n",
    "**1st Model Choice**: [`all-MiniLM-L6-v2`](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2)\n",
    "- Good balance of speed and quality\n",
    "- 384-dimensional embeddings\n",
    "- Well-tested for retrieval tasks\n",
    "\n",
    "**NOTE:**: this model by default, any input text longer than 256 word pieces is truncated.\n",
    "\n",
    "**How embeddings work**:\n",
    "- Similar texts have similar vectors\n",
    "- Mathematical distance = semantic similarity\n",
    "- Enables meaning-based search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1671a226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded 2 text chunks\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Load Text Chunks from Previous Notebook\n",
    "try:\n",
    "    with open(\"../2_data/processed/text_chunks.pkl\", \"rb\") as f:\n",
    "        chunks = pickle.load(f)\n",
    "    print(f\"‚úÖ Loaded {len(chunks)} text chunks\")\n",
    "except FileNotFoundError:\n",
    "    print(\"‚ùå Please run the PDF processing notebook first!\")\n",
    "    chunks = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78ec8a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of first chunk: <class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "# DEBUG: Check what type we have\n",
    "print(f\"Type of first chunk: {type(chunks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77540cd2",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# FIX: Convert strings to Document objects if needed\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[43mchunks\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m      3\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33müîÑ Converting strings to Document objects...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m     chunks = [Document(page_content=chunk) \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m chunks]\n",
      "\u001b[31mKeyError\u001b[39m: 0"
     ]
    }
   ],
   "source": [
    "# FIX: Convert strings to Document objects if needed\n",
    "if isinstance(chunks[0], str):\n",
    "    print(\"üîÑ Converting strings to Document objects...\")\n",
    "    chunks = [Document(page_content=chunk) for chunk in chunks]\n",
    "    print(\"‚úÖ Conversion completed!\")\n",
    "\n",
    "print(f\"First chunk preview: {chunks[0].page_content[:100]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68ade04b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tx/45hhw1yn48jfdqn2hmnhbhvw0000gn/T/ipykernel_55208/2948694227.py:2: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ac0eb3869144f68b54d1770f0d5d36c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6a3f9724f3548be83df369deddefab8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64159918d65d436c83299075181bfa58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f66a711d3a941ea9ff2ae1b708f9896",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f85982b793874c1bbe80bd6204e6cbd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88d657f14d08475995dc7990f921bb94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e45aec3a4c9a44b89ec63fda61c56460",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6840c57d3db4757aa097ed3d861be04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad70d4ab8b12462682c6c3a7c2373e92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5869cd35dd84bc4a1f52d2323c12226",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/guillermo/venvs/langchain_venv/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3359cced576341d19bfb91333a3666c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Embeddings model loaded!\n",
      "üìê Embedding dimension: 384\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Initialize Embeddings\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Embeddings model loaded!\")\n",
    "\n",
    "# Test the embeddings\n",
    "sample_text = \"GDPR compliance for small businesses\"\n",
    "sample_embedding = embeddings.embed_query(sample_text)\n",
    "print(f\"üìê Embedding dimension: {len(sample_embedding)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76107054",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'page_content'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Cell 4: Create Vector Database\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m vectorstore = \u001b[43mChroma\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_documents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m=\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpersist_directory\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m../2_data/processed/chroma_db\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m      6\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m‚úÖ Vector database created and persisted!\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venvs/langchain_venv/lib/python3.11/site-packages/langchain_community/vectorstores/chroma.py:885\u001b[39m, in \u001b[36mChroma.from_documents\u001b[39m\u001b[34m(cls, documents, embedding, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[39m\n\u001b[32m    852\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m    853\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfrom_documents\u001b[39m(\n\u001b[32m    854\u001b[39m     \u001b[38;5;28mcls\u001b[39m: Type[Chroma],\n\u001b[32m   (...)\u001b[39m\u001b[32m    865\u001b[39m     **kwargs: Any,\n\u001b[32m    866\u001b[39m ) -> Chroma:\n\u001b[32m    867\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Create a Chroma vectorstore from a list of documents.\u001b[39;00m\n\u001b[32m    868\u001b[39m \n\u001b[32m    869\u001b[39m \u001b[33;03m    If a persist_directory is specified, the collection will be persisted there.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    883\u001b[39m \u001b[33;03m        Chroma: Chroma vectorstore.\u001b[39;00m\n\u001b[32m    884\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m885\u001b[39m     texts = \u001b[43m[\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpage_content\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    886\u001b[39m     metadatas = [doc.metadata \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[32m    887\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m.from_texts(\n\u001b[32m    888\u001b[39m         texts=texts,\n\u001b[32m    889\u001b[39m         embedding=embedding,\n\u001b[32m   (...)\u001b[39m\u001b[32m    897\u001b[39m         **kwargs,\n\u001b[32m    898\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venvs/langchain_venv/lib/python3.11/site-packages/langchain_community/vectorstores/chroma.py:885\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    852\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m    853\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfrom_documents\u001b[39m(\n\u001b[32m    854\u001b[39m     \u001b[38;5;28mcls\u001b[39m: Type[Chroma],\n\u001b[32m   (...)\u001b[39m\u001b[32m    865\u001b[39m     **kwargs: Any,\n\u001b[32m    866\u001b[39m ) -> Chroma:\n\u001b[32m    867\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Create a Chroma vectorstore from a list of documents.\u001b[39;00m\n\u001b[32m    868\u001b[39m \n\u001b[32m    869\u001b[39m \u001b[33;03m    If a persist_directory is specified, the collection will be persisted there.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    883\u001b[39m \u001b[33;03m        Chroma: Chroma vectorstore.\u001b[39;00m\n\u001b[32m    884\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m885\u001b[39m     texts = [\u001b[43mdoc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpage_content\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[32m    886\u001b[39m     metadatas = [doc.metadata \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[32m    887\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m.from_texts(\n\u001b[32m    888\u001b[39m         texts=texts,\n\u001b[32m    889\u001b[39m         embedding=embedding,\n\u001b[32m   (...)\u001b[39m\u001b[32m    897\u001b[39m         **kwargs,\n\u001b[32m    898\u001b[39m     )\n",
      "\u001b[31mAttributeError\u001b[39m: 'str' object has no attribute 'page_content'"
     ]
    }
   ],
   "source": [
    "# Cell 4: Create Vector Database\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=embeddings,\n",
    "    persist_directory=\"../2_data/processed/chroma_db\"\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Vector database created and persisted!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06188dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Test Similarity Search\n",
    "print(\"üîç Testing similarity search...\")\n",
    "\n",
    "test_queries = [\n",
    "    \"data retention periods\",\n",
    "    \"customer consent for marketing\",\n",
    "    \"employee record keeping\"\n",
    "]\n",
    "\n",
    "for query in test_queries:\n",
    "    print(f\"\\nQuery: '{query}'\")\n",
    "    results = vectorstore.similarity_search(query, k=2)\n",
    "    \n",
    "    for i, result in enumerate(results):\n",
    "        print(f\"Result {i+1}: {result.page_content[:100]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931de83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Verify Database Persistence\n",
    "# Let's reload to verify it works\n",
    "vectorstore_reloaded = Chroma(\n",
    "    persist_directory=\"data/processed/chroma_db\",\n",
    "    embedding_function=embeddings\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Vector database reloaded successfully!\")\n",
    "print(f\"üìä Collection count: {vectorstore_reloaded._collection.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47518c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Advanced Search Tests\n",
    "print(\"\\nüéØ Testing different search types:\")\n",
    "\n",
    "# Search with metadata filter (if we had any)\n",
    "results = vectorstore_reloaded.similarity_search(\n",
    "    \"data breach procedures\", \n",
    "    k=3\n",
    ")\n",
    "\n",
    "print(f\"Found {len(results)} relevant documents for 'data breach procedures'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1a49c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Prepare for Next Notebook\n",
    "print(\"\\n‚úÖ Vector database ready for RAG agent!\")\n",
    "print(\"Next: Create the question-answering system\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LangChain",
   "language": "python",
   "name": "langchain_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
