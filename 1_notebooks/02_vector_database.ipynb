{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3f0f5c1",
   "metadata": {},
   "source": [
    "# üóÑÔ∏è GDPR Compliance Agent - Notebook 2: Vector Database\n",
    "\n",
    "## üìã Table of Contents\n",
    "1. [Overview](#overview)\n",
    "2. [Load Previous Work](#load-previous-work)\n",
    "3. [Embeddings Setup](#embeddings-setup)\n",
    "4. [Vector Database Creation](#vector-database-creation)\n",
    "5. [Similarity Search Testing](#similarity-search-testing)\n",
    "6. [Persistence Verification](#persistence-verification)\n",
    "7. [Advanced Search Features](#advanced-search-features)\n",
    "8. [Preparation for Next Step](#preparation-for-next-step)\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Overview\n",
    "\n",
    "**Goal**: Create a searchable knowledge base from our text chunks\n",
    "\n",
    "**This Notebook Focus**: \n",
    "- Generate embeddings for text chunks\n",
    "- Store in vector database (ChromaDB)\n",
    "- Test retrieval capabilities\n",
    "\n",
    "**Key Concepts**:\n",
    "- **Embeddings**: Numerical representations of text\n",
    "- **Vector Database**: Specialized storage for embeddings\n",
    "- **Similarity Search**: Find relevant documents based on meaning\n",
    "\n",
    "---\n",
    "\n",
    "## üì• Load Previous Work\n",
    "\n",
    "*Load the text chunks we created in Notebook 1*\n",
    "\n",
    "**What we're loading**:\n",
    "- Processed text chunks\n",
    "- Metadata about each chunk\n",
    "\n",
    "**Error Handling**: Check if previous steps were completed successfully"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "293e2148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Setting up Vector Database...\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Setup and Load Previous Work\n",
    "import os\n",
    "import pickle\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "print(\"üöÄ Setting up Vector Database...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8eb804",
   "metadata": {},
   "source": [
    "## üî¢ Embeddings Setup\n",
    "\n",
    "*Initialize the embedding model that converts text to numbers*\n",
    "\n",
    "**1st Model Choice**: [`all-MiniLM-L6-v2`](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2)\n",
    "- Good balance of speed and quality\n",
    "- 384-dimensional embeddings\n",
    "- Well-tested for retrieval tasks\n",
    "\n",
    "**NOTE:**: this model by default, any input text longer than 256 word pieces is truncated.\n",
    "\n",
    "**How embeddings work**:\n",
    "- Similar texts have similar vectors\n",
    "- Mathematical distance = semantic similarity\n",
    "- Enables meaning-based search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1671a226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded 2 text chunks\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Load Text Chunks from Previous Notebook\n",
    "try:\n",
    "    with open(\"../2_data/processed/text_chunks.pkl\", \"rb\") as f:\n",
    "        chunks = pickle.load(f)\n",
    "    print(f\"‚úÖ Loaded {len(chunks)} text chunks\")\n",
    "except FileNotFoundError:\n",
    "    print(\"‚ùå Please run the PDF processing notebook first!\")\n",
    "    chunks = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78ec8a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of first chunk: <class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "# DEBUG: Check what type we have\n",
    "print(f\"Type of first chunk: {type(chunks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77540cd2",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# FIX: Convert strings to Document objects if needed\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[43mchunks\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m      3\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33müîÑ Converting strings to Document objects...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m     chunks = [Document(page_content=chunk) \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m chunks]\n",
      "\u001b[31mKeyError\u001b[39m: 0"
     ]
    }
   ],
   "source": [
    "# FIX: Convert strings to Document objects if needed\n",
    "if isinstance(chunks[0], str):\n",
    "    print(\"üîÑ Converting strings to Document objects...\")\n",
    "    chunks = [Document(page_content=chunk) for chunk in chunks]\n",
    "    print(\"‚úÖ Conversion completed!\")\n",
    "\n",
    "print(f\"First chunk preview: {chunks[0].page_content[:100]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68ade04b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tx/45hhw1yn48jfdqn2hmnhbhvw0000gn/T/ipykernel_55208/2948694227.py:2: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ac0eb3869144f68b54d1770f0d5d36c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6a3f9724f3548be83df369deddefab8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64159918d65d436c83299075181bfa58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f66a711d3a941ea9ff2ae1b708f9896",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f85982b793874c1bbe80bd6204e6cbd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88d657f14d08475995dc7990f921bb94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e45aec3a4c9a44b89ec63fda61c56460",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6840c57d3db4757aa097ed3d861be04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad70d4ab8b12462682c6c3a7c2373e92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5869cd35dd84bc4a1f52d2323c12226",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/guillermo/venvs/langchain_venv/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3359cced576341d19bfb91333a3666c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Embeddings model loaded!\n",
      "üìê Embedding dimension: 384\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Initialize Embeddings\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Embeddings model loaded!\")\n",
    "\n",
    "# Test the embeddings\n",
    "sample_text = \"GDPR compliance for small businesses\"\n",
    "sample_embedding = embeddings.embed_query(sample_text)\n",
    "print(f\"üìê Embedding dimension: {len(sample_embedding)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76107054",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'page_content'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Cell 4: Create Vector Database\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m vectorstore = \u001b[43mChroma\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_documents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m=\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpersist_directory\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m../2_data/processed/chroma_db\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m      6\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m‚úÖ Vector database created and persisted!\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venvs/langchain_venv/lib/python3.11/site-packages/langchain_community/vectorstores/chroma.py:885\u001b[39m, in \u001b[36mChroma.from_documents\u001b[39m\u001b[34m(cls, documents, embedding, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[39m\n\u001b[32m    852\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m    853\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfrom_documents\u001b[39m(\n\u001b[32m    854\u001b[39m     \u001b[38;5;28mcls\u001b[39m: Type[Chroma],\n\u001b[32m   (...)\u001b[39m\u001b[32m    865\u001b[39m     **kwargs: Any,\n\u001b[32m    866\u001b[39m ) -> Chroma:\n\u001b[32m    867\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Create a Chroma vectorstore from a list of documents.\u001b[39;00m\n\u001b[32m    868\u001b[39m \n\u001b[32m    869\u001b[39m \u001b[33;03m    If a persist_directory is specified, the collection will be persisted there.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    883\u001b[39m \u001b[33;03m        Chroma: Chroma vectorstore.\u001b[39;00m\n\u001b[32m    884\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m885\u001b[39m     texts = \u001b[43m[\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpage_content\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    886\u001b[39m     metadatas = [doc.metadata \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[32m    887\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m.from_texts(\n\u001b[32m    888\u001b[39m         texts=texts,\n\u001b[32m    889\u001b[39m         embedding=embedding,\n\u001b[32m   (...)\u001b[39m\u001b[32m    897\u001b[39m         **kwargs,\n\u001b[32m    898\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venvs/langchain_venv/lib/python3.11/site-packages/langchain_community/vectorstores/chroma.py:885\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    852\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m    853\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfrom_documents\u001b[39m(\n\u001b[32m    854\u001b[39m     \u001b[38;5;28mcls\u001b[39m: Type[Chroma],\n\u001b[32m   (...)\u001b[39m\u001b[32m    865\u001b[39m     **kwargs: Any,\n\u001b[32m    866\u001b[39m ) -> Chroma:\n\u001b[32m    867\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Create a Chroma vectorstore from a list of documents.\u001b[39;00m\n\u001b[32m    868\u001b[39m \n\u001b[32m    869\u001b[39m \u001b[33;03m    If a persist_directory is specified, the collection will be persisted there.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    883\u001b[39m \u001b[33;03m        Chroma: Chroma vectorstore.\u001b[39;00m\n\u001b[32m    884\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m885\u001b[39m     texts = [\u001b[43mdoc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpage_content\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[32m    886\u001b[39m     metadatas = [doc.metadata \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[32m    887\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m.from_texts(\n\u001b[32m    888\u001b[39m         texts=texts,\n\u001b[32m    889\u001b[39m         embedding=embedding,\n\u001b[32m   (...)\u001b[39m\u001b[32m    897\u001b[39m         **kwargs,\n\u001b[32m    898\u001b[39m     )\n",
      "\u001b[31mAttributeError\u001b[39m: 'str' object has no attribute 'page_content'"
     ]
    }
   ],
   "source": [
    "# Cell 4: Create Vector Database\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=embeddings,\n",
    "    persist_directory=\"../2_data/processed/chroma_db\"\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Vector database created and persisted!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06188dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Test Similarity Search\n",
    "print(\"üîç Testing similarity search...\")\n",
    "\n",
    "test_queries = [\n",
    "    \"data retention periods\",\n",
    "    \"customer consent for marketing\",\n",
    "    \"employee record keeping\"\n",
    "]\n",
    "\n",
    "for query in test_queries:\n",
    "    print(f\"\\nQuery: '{query}'\")\n",
    "    results = vectorstore.similarity_search(query, k=2)\n",
    "    \n",
    "    for i, result in enumerate(results):\n",
    "        print(f\"Result {i+1}: {result.page_content[:100]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931de83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Verify Database Persistence\n",
    "# Let's reload to verify it works\n",
    "vectorstore_reloaded = Chroma(\n",
    "    persist_directory=\"data/processed/chroma_db\",\n",
    "    embedding_function=embeddings\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Vector database reloaded successfully!\")\n",
    "print(f\"üìä Collection count: {vectorstore_reloaded._collection.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47518c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Advanced Search Tests\n",
    "print(\"\\nüéØ Testing different search types:\")\n",
    "\n",
    "# Search with metadata filter (if we had any)\n",
    "results = vectorstore_reloaded.similarity_search(\n",
    "    \"data breach procedures\", \n",
    "    k=3\n",
    ")\n",
    "\n",
    "print(f\"Found {len(results)} relevant documents for 'data breach procedures'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1a49c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Prepare for Next Notebook\n",
    "print(\"\\n‚úÖ Vector database ready for RAG agent!\")\n",
    "print(\"Next: Create the question-answering system\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LangChain",
   "language": "python",
   "name": "langchain_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
