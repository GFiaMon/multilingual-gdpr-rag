{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46cda769",
   "metadata": {},
   "source": [
    "# ğŸš€ GDPR Compliance Agent - Notebook 1: PDF Processing\n",
    "\n",
    "## ğŸ“‹ Table of Contents\n",
    "1. [Project Overview](#project-overview)\n",
    "2. [Setup & Imports](#setup-imports)\n",
    "3. [Create Sample Data](#create-sample-data)\n",
    "4. [Load & Explore Data](#load-explore-data)\n",
    "5. [Text Chunking](#text-chunking)\n",
    "6. [Chunk Analysis](#chunk-analysis)\n",
    "7. [German PDF Extraction](#german-pdf-extraction)\n",
    "8. [Save Results](#save-results)\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ Project Overview\n",
    "\n",
    "**Goal**: Create a GDPR compliance assistant that can answer questions about data protection guidelines.\n",
    "\n",
    "**This Notebook Focus**: Process text documents and prepare them for the vector database.\n",
    "\n",
    "**Key Steps**:\n",
    "- Load sample GDPR handbook\n",
    "- Extract text from German PDF\n",
    "- Split text into manageable chunks\n",
    "- Prepare for embedding generation\n",
    "\n",
    "---\n",
    "\n",
    "## âš™ï¸ Setup & Imports\n",
    "\n",
    "*Import required libraries and set up the environment*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02793c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pypdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42fbbdce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Setup and Imports\n",
    "import os\n",
    "import sys\n",
    "from langchain.document_loaders import TextLoader, PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "import pickle\n",
    "\n",
    "print(\"âœ… Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd89d5e",
   "metadata": {},
   "source": [
    "## ğŸ“„ Create Sample Data\n",
    "\n",
    "*Since we're starting with English data, we'll create a sample GDPR handbook*\n",
    "\n",
    "**What we're creating**:\n",
    "- Basic GDPR principles\n",
    "- Customer data handling rules  \n",
    "- Employee data guidelines\n",
    "- Data breach procedures\n",
    "\n",
    "*This simulates a real company compliance handbook*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a09fb24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cell 2: Create Sample English Data\n",
    "sample_english_content = \"\"\"\n",
    "GDPR COMPLIANCE HANDBOOK FOR SMALL BUSINESSES\n",
    "\n",
    "SECTION 1: BASIC PRINCIPLES\n",
    "\n",
    "Article 1: Data Protection Principles\n",
    "Personal data must be processed lawfully, fairly, and transparently. \n",
    "Businesses must clearly state why they collect data and how it will be used.\n",
    "\n",
    "Article 2: Lawful Basis for Processing\n",
    "You can process personal data when:\n",
    "- You have explicit consent from the individual\n",
    "- It's necessary for a contract\n",
    "- It's required by law\n",
    "- It's in the legitimate interests of your business\n",
    "\n",
    "Article 3: Data Minimization\n",
    "Only collect data that is strictly necessary for your specific purpose.\n",
    "Do not collect excessive or irrelevant information.\n",
    "\n",
    "SECTION 2: CUSTOMER DATA HANDLING\n",
    "\n",
    "Article 4: Customer Consent\n",
    "For marketing emails, you must have explicit opt-in consent.\n",
    "Pre-ticked boxes or assumed consent are not valid.\n",
    "Customers must be able to withdraw consent easily.\n",
    "\n",
    "Article 5: Data Retention\n",
    "Keep customer data only as long as necessary:\n",
    "- Invoices and contracts: 10 years\n",
    "- Marketing consent: 2 years (unless renewed)\n",
    "- Customer complaints: 6 years\n",
    "\n",
    "Article 6: Data Subject Rights\n",
    "Customers have the right to:\n",
    "- Access their personal data\n",
    "- Correct inaccurate data\n",
    "- Request deletion of their data\n",
    "- Object to data processing\n",
    "\n",
    "SECTION 3: EMPLOYEE DATA\n",
    "\n",
    "Article 7: Employee Records\n",
    "Keep employee data secure and confidential:\n",
    "- Employment contracts: 6 years after employment ends\n",
    "- Salary records: 10 years\n",
    "- Performance reviews: 3 years\n",
    "\n",
    "Article 8: Recruitment Data\n",
    "Unsuccessful applicant data: 6 months\n",
    "Interview notes: 12 months\n",
    "\n",
    "SECTION 4: DATA BREACH PROCEDURES\n",
    "\n",
    "Article 9: Breach Notification\n",
    "Report data breaches to authorities within 72 hours.\n",
    "Inform affected individuals if there is high risk to their rights.\n",
    "Document all breaches for internal records.\n",
    "\n",
    "Article 10: Security Measures\n",
    "Implement appropriate technical security measures.\n",
    "Train staff on data protection principles.\n",
    "Regularly review and update security practices.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54ccc308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Sample English handbook created!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Save sample data\n",
    "os.makedirs(\"../2_data/raw\", exist_ok=True)\n",
    "with open(\"../2_data/raw/sample_english_handbook.txt\", \"w\") as f:\n",
    "    f.write(sample_english_content)\n",
    "\n",
    "print(\"âœ… Sample English handbook created!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d5ff1b",
   "metadata": {},
   "source": [
    "## ğŸ” Load & Explore Data\n",
    "\n",
    "*Load our sample data and examine its structure*\n",
    "\n",
    "**Key Questions**:\n",
    "- How much text do we have?\n",
    "- What's the content structure?\n",
    "- Are there clear sections we can use?\n",
    "\n",
    "*Understanding your data is crucial for good chunking strategy*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfefa024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“„ Number of documents: 1\n",
      "ğŸ“ First 500 characters:\n",
      "\n",
      "GDPR COMPLIANCE HANDBOOK FOR SMALL BUSINESSES\n",
      "\n",
      "SECTION 1: BASIC PRINCIPLES\n",
      "\n",
      "Article 1: Data Protection Principles\n",
      "Personal data must be processed lawfully, fairly, and transparently. \n",
      "Businesses must clearly state why they collect data and how it will be used.\n",
      "\n",
      "Article 2: Lawful Basis for Processing\n",
      "You can process personal data when:\n",
      "- You have explicit consent from the individual\n",
      "- It's necessary for a contract\n",
      "- It's required by law\n",
      "- It's in the legitimate interests of your business\n",
      "\n",
      "Articl...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Cell 3: Load and Explore the Data\n",
    "loader = TextLoader(\"../2_data/raw/sample_english_handbook.txt\", encoding='utf-8')\n",
    "documents = loader.load()\n",
    "\n",
    "print(f\"ğŸ“„ Number of documents: {len(documents)}\")\n",
    "print(f\"ğŸ“ First 500 characters:\")\n",
    "print(documents[0].page_content[:500] + \"...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997baee0",
   "metadata": {},
   "source": [
    "## âœ‚ï¸ Text Chunking\n",
    "\n",
    "*Split the document into smaller pieces for processing*\n",
    "\n",
    "**Why chunking matters**:\n",
    "- LLMs have context window limits\n",
    "- Smaller chunks are easier to search\n",
    "- Better precision in retrieval\n",
    "\n",
    "**Parameters we're using**:\n",
    "- `chunk_size=500`: Balance between context and precision\n",
    "- `chunk_overlap=50`: Maintain context between chunks\n",
    "- Smart separators: Prefer natural breaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "604a8f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ‚ï¸ Created 5 text chunks\n",
      "\n",
      "ğŸ“‹ Sample chunk:\n",
      "Content: Article 5: Data Retention\n",
      "Keep customer data only as long as necessary:\n",
      "- Invoices and contracts: 10 years\n",
      "- Marketing consent: 2 years (unless renewed)\n",
      "- Customer complaints: 6 years\n",
      "\n",
      "Article 6: Data...\n",
      "Length: 386 characters\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Split Text into Chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=50,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \". \", \"! \", \"? \", \" \", \"\"]\n",
    ")\n",
    "\n",
    "en_sample_chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "print(f\"âœ‚ï¸ Created {len(en_sample_chunks)} text chunks\")\n",
    "print(\"\\nğŸ“‹ Sample chunk:\")\n",
    "print(f\"Content: {en_sample_chunks[2].page_content[:200]}...\")\n",
    "print(f\"Length: {len(en_sample_chunks[2].page_content)} characters\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc86f42f",
   "metadata": {},
   "source": [
    "## ğŸ“Š Chunk Analysis\n",
    "\n",
    "*Examine the results of our chunking strategy*\n",
    "\n",
    "**What to check**:\n",
    "- Number of chunks created\n",
    "- Size distribution\n",
    "- Content quality\n",
    "\n",
    "**Common Issues**:\n",
    "- âŒ Chunks too small (lose context)\n",
    "- âŒ Chunks too large (irrelevant info)\n",
    "- âœ… Balanced chunks (optimal retrieval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df7afaea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Chunk statistics:\n",
      "Min length: 338\n",
      "Max length: 491\n",
      "Avg length: 399.2\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Examine Chunk Distribution\n",
    "chunk_lengths = [len(chunk.page_content) for chunk in en_sample_chunks]\n",
    "\n",
    "print(f\"ğŸ“Š Chunk statistics:\")\n",
    "print(f\"Min length: {min(chunk_lengths)}\")\n",
    "print(f\"Max length: {max(chunk_lengths)}\")\n",
    "print(f\"Avg length: {sum(chunk_lengths)/len(chunk_lengths):.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23f49f2",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6003c135",
   "metadata": {},
   "source": [
    "## ğŸ‡©ğŸ‡ª German PDF Extraction\n",
    "\n",
    "*Now let's extract text from your actual German PDF*\n",
    "\n",
    "**What we'll do**:\n",
    "1. Check if German PDF exists\n",
    "2. Extract text automatically\n",
    "3. Process German text chunks\n",
    "4. Compare with English version\n",
    "\n",
    "**Important**: We'll use the same chunking strategy for both languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee9ee5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Extract Text from German PDF\n",
    "def extract_german_pdf(pdf_path):\n",
    "    \"\"\"Extract text from German PDF automatically\"\"\"\n",
    "    try:\n",
    "        print(f\"ğŸ” Attempting to extract text from: {pdf_path}\")\n",
    "        \n",
    "        # Check if file exists\n",
    "        if not os.path.exists(pdf_path):\n",
    "            print(f\"âŒ File not found: {pdf_path}\")\n",
    "            print(\"ğŸ’¡ Please place your German PDF in the data/raw/ folder\")\n",
    "            return None\n",
    "        \n",
    "        # Load PDF using PyPDFLoader\n",
    "        loader = PyPDFLoader(pdf_path)\n",
    "        german_documents = loader.load()\n",
    "        \n",
    "        print(f\"âœ… Successfully extracted {len(german_documents)} pages from German PDF\")\n",
    "        \n",
    "        # Show sample content from first page\n",
    "        if german_documents:\n",
    "            first_page_content = german_documents[0].page_content\n",
    "            print(f\"\\nğŸ“„ Sample from first page (first 300 characters):\")\n",
    "            print(first_page_content[:300] + \"...\" if len(first_page_content) > 300 else first_page_content)\n",
    "            \n",
    "            # Check if text looks like German\n",
    "            german_keywords = ['der', 'die', 'das', 'und', 'fÃ¼r', 'von', 'mit', 'Datenschutz', 'DSGVO']\n",
    "            found_keywords = [word for word in german_keywords if word in first_page_content]\n",
    "            print(f\"\\nğŸ”¤ German keywords found: {found_keywords}\")\n",
    "        \n",
    "        return german_documents\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error extracting PDF: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67f24dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Attempting to extract text from: ../2_data/raw/ZDH_LEITFADEN_DATENSCHUTZ_BETRIEBE_HANDWERKER.pdf\n",
      "âœ… Successfully extracted 99 pages from German PDF\n",
      "\n",
      "ğŸ“„ Sample from first page (first 300 characters):\n",
      "Leitfaden \n",
      "Datenschutzrecht \n",
      "Was Betriebe zu beachten haben \n",
      " \n",
      " \n",
      "Stand: November 2020 \n",
      " \n",
      "Abteilung Organisation und Recht\n",
      "\n",
      "ğŸ”¤ German keywords found: ['und', 'Datenschutz']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Try to extract German PDF\n",
    "german_pdf_path = \"../2_data/raw/ZDH_LEITFADEN_DATENSCHUTZ_BETRIEBE_HANDWERKER.pdf\"\n",
    "german_documents = extract_german_pdf(german_pdf_path)\n",
    "\n",
    "# If no German PDF found, create a sample German text for testing\n",
    "if german_documents is None:\n",
    "    print(\"\\nğŸ“ Creating sample German text for testing...\")\n",
    "    \n",
    "    sample_german_content = \"\"\"\n",
    "    Datenschutz-Handbuch fÃ¼r Handwerksbetriebe\n",
    "    \n",
    "    Kapitel 1: Grundlagen der DSGVO\n",
    "    \n",
    "    Artikel 1: DatenschutzgrundsÃ¤tze\n",
    "    Personenbezogene Daten mÃ¼ssen rechtmÃ¤ÃŸig, nach Treu und Glauben und transparent verarbeitet werden.\n",
    "    Unternehmen mÃ¼ssen klar angeben, warum sie Daten sammeln und wie sie verwendet werden.\n",
    "    \n",
    "    Artikel 2: Rechtsgrundlagen der Verarbeitung\n",
    "    Sie dÃ¼rfen personenbezogene Daten verarbeiten, wenn:\n",
    "    - Die betroffene Person eingewilligt hat\n",
    "    - Die Verarbeitung fÃ¼r einen Vertrag erforderlich ist\n",
    "    - Eine gesetzliche Verpflichtung besteht\n",
    "    - Berechtigte Interessen des Unternehmens vorliegen\n",
    "    \n",
    "    Artikel 3: Datenminimierung\n",
    "    Sammeln Sie nur Daten, die fÃ¼r den spezifischen Zweck unbedingt erforderlich sind.\n",
    "    Vermeiden Sie excessive oder irrelevante Informationen.\n",
    "    \n",
    "    Kapitel 2: Umgang mit Kundendaten\n",
    "    \n",
    "    Artikel 4: Kunden Einwilligung\n",
    "    FÃ¼r Marketing-E-Mails ist eine ausdrÃ¼ckliche Opt-In-Einwilligung erforderlich.\n",
    "    Vorangekreuzte KÃ¤stchen oder stillschweigende Zustimmung sind nicht gÃ¼ltig.\n",
    "    Kunden mÃ¼ssen ihre Einwilligung jederzeit widerrufen kÃ¶nnen.\n",
    "    \n",
    "    Artikel 5: Aufbewahrungsfristen\n",
    "    Bewahren Sie Kundendaten nur so lange auf wie nÃ¶tig:\n",
    "    - Rechnungen und VertrÃ¤ge: 10 Jahre\n",
    "    - Marketing-Einwilligungen: 2 Jahre (sofern nicht erneuert)\n",
    "    - Kundenbeschwerden: 6 Jahre\n",
    "    \"\"\"\n",
    "    \n",
    "    # Save sample German text\n",
    "    with open(\"../2_data/raw/sample_german_handbook.txt\", \"w\", encoding='utf-8') as f:\n",
    "        f.write(sample_german_content)\n",
    "    \n",
    "    # Load the sample German text\n",
    "    loader = TextLoader(\"../2_data/raw/sample_german_handbook.txt\", encoding='utf-8')\n",
    "    german_documents = loader.load()\n",
    "    \n",
    "    print(\"âœ… Sample German handbook created for testing!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33a4deeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ”¨ Processing German text chunks...\n",
      "âœ‚ï¸ Created 379 German text chunks\n",
      "ğŸ“Š German chunk sizes: [121, 471, 447]...\n",
      "\n",
      "ğŸ“‹ Sample German chunk:\n",
      "Content: Vorwort \n",
      "Seit dem 25. Mai 2018 gelten in allen Mitgliedstaaten der EuropÃ¤ischen Union neue Daten-\n",
      "schutzregeln. Mit der Reform soll sichergestellt werden, dass in allen Mitgliedstaaten derselbe \n",
      "Daten...\n",
      "\n",
      "ğŸ“ˆ Comparison:\n",
      "English chunks: 5\n",
      "German chunks: 379\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Process German Text Chunks\n",
    "if german_documents:\n",
    "    print(\"\\nğŸ”¨ Processing German text chunks...\")\n",
    "    \n",
    "    # Use the same text splitter for consistency\n",
    "    german_chunks = text_splitter.split_documents(german_documents)\n",
    "    \n",
    "    print(f\"âœ‚ï¸ Created {len(german_chunks)} German text chunks\")\n",
    "    print(f\"ğŸ“Š German chunk sizes: {[len(chunk.page_content) for chunk in german_chunks[:3]]}...\")\n",
    "    \n",
    "    # Show sample German chunk\n",
    "    if german_chunks:\n",
    "        print(f\"\\nğŸ“‹ Sample German chunk:\")\n",
    "        print(f\"Content: {german_chunks[1].page_content[:200]}...\")\n",
    "        \n",
    "    # Compare English vs German\n",
    "    print(f\"\\nğŸ“ˆ Comparison:\")\n",
    "    print(f\"English chunks: {len(en_sample_chunks)}\")\n",
    "    print(f\"German chunks: {len(german_chunks)}\")\n",
    "else:\n",
    "    print(\"âŒ No German documents to process\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11a03eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'producer': 'MicrosoftÂ® Word fÃ¼r Office 365', 'creator': 'MicrosoftÂ® Word fÃ¼r Office 365', 'creationdate': '2020-11-06T11:24:59+01:00', 'author': 'Kasper, Lisa', 'moddate': '2020-11-06T11:24:59+01:00', 'source': '../2_data/raw/ZDH_LEITFADEN_DATENSCHUTZ_BETRIEBE_HANDWERKER.pdf', 'total_pages': 99, 'page': 98, 'page_label': '99'}\n",
      "Ort, Datum, Unterschrift \n",
      " \n",
      " \n",
      " \n",
      "Die Datenverarbeitung ist fÃ¼r die Kontaktaufnahme per Telefon, Fax und E -Mail erforderlich und be-\n",
      "ruht auf Artikel 6 Abs. 1 a) DSGVO. Eine Weitergabe der Daten an Dritte findet nicht statt. Die Daten \n",
      "werden gelÃ¶scht, sobald sie fÃ¼r den Zweck ihrer Verarbeitung nicht mehr erforderlich sind.  \n",
      " \n",
      "Sie sind berechtigt, Auskunft der bei uns Ã¼ber Sie gespeicherten Daten zu beantragen sowie bei Un-\n"
     ]
    }
   ],
   "source": [
    "print(german_chunks[377].metadata)\n",
    "print(german_chunks[377].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b185776e",
   "metadata": {},
   "source": [
    "## ğŸ’¾ Save Results\n",
    "\n",
    "*Save processed chunks for the next notebook*\n",
    "\n",
    "**What we're saving**:\n",
    "- English text chunks with metadata\n",
    "- German text chunks with metadata  \n",
    "- Ready for embedding generation\n",
    "\n",
    "**Next Steps**:\n",
    "- Vector database setup in Notebook 2\n",
    "- Multilingual embedding generation\n",
    "- Cross-language search testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9aad7496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… All text chunks saved for next notebook!\n",
      "ğŸ“ English chunks: 5\n",
      "ğŸ“ German chunks: 379\n",
      "\n",
      "ğŸ‰ Ready for Notebook 2: Vector Database Setup!\n",
      "â¡ï¸ Next: We'll create embeddings and set up semantic search for both languages\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Save All Chunks for Next Notebook\n",
    "\n",
    "# Combine or save separately based on your needs\n",
    "all_chunks = {\n",
    "    'english': en_sample_chunks,\n",
    "    'german': german_chunks if 'german_chunks' in locals() else []\n",
    "}\n",
    "\n",
    "os.makedirs(\"../2_data/processed\", exist_ok=True)\n",
    "with open(\"../2_data/processed/text_chunks.pkl\", \"wb\") as f:\n",
    "    pickle.dump(all_chunks, f)\n",
    "\n",
    "print(\"âœ… All text chunks saved for next notebook!\")\n",
    "print(f\"ğŸ“ English chunks: {len(en_sample_chunks)}\")\n",
    "if 'german_chunks' in locals():\n",
    "    print(f\"ğŸ“ German chunks: {len(german_chunks)}\")\n",
    "\n",
    "print(\"\\nğŸ‰ Ready for Notebook 2: Vector Database Setup!\")\n",
    "print(\"â¡ï¸ Next: We'll create embeddings and set up semantic search for both languages\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cddba68a",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "-----"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LangChain",
   "language": "python",
   "name": "langchain_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
