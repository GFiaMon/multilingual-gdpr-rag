{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46cda769",
   "metadata": {},
   "source": [
    "# üöÄ GDPR Compliance Agent - Notebook 1: PDF Processing\n",
    "\n",
    "## üìã Table of Contents\n",
    "1. [Project Overview](#project-overview)\n",
    "2. [Setup & Imports](#setup-imports)\n",
    "3. [Create Sample Data](#create-sample-data)\n",
    "4. [Load & Explore Data](#load-explore-data)\n",
    "5. [Text Chunking](#text-chunking)\n",
    "6. [Chunk Analysis](#chunk-analysis)\n",
    "7. [German PDF Extraction](#german-pdf-extraction)\n",
    "8. [Save Results](#save-results)\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Project Overview\n",
    "\n",
    "**Goal**: Create a GDPR compliance assistant that can answer questions about data protection guidelines.\n",
    "\n",
    "**This Notebook Focus**: Process text documents and prepare them for the vector database.\n",
    "\n",
    "**Key Steps**:\n",
    "- Load sample GDPR handbook\n",
    "- Extract text from German PDF\n",
    "- Split text into manageable chunks\n",
    "- Prepare for embedding generation\n",
    "\n",
    "---\n",
    "\n",
    "## ‚öôÔ∏è Setup & Imports\n",
    "\n",
    "*Import required libraries and set up the environment*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02793c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pypdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42fbbdce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Setup and Imports\n",
    "import os\n",
    "import sys\n",
    "from langchain.document_loaders import TextLoader, PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "import pickle\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd89d5e",
   "metadata": {},
   "source": [
    "## üìÑ Create Sample Data\n",
    "\n",
    "*Since we're starting with English data, we'll create a sample GDPR handbook*\n",
    "\n",
    "**What we're creating**:\n",
    "- Basic GDPR principles\n",
    "- Customer data handling rules  \n",
    "- Employee data guidelines\n",
    "- Data breach procedures\n",
    "\n",
    "*This simulates a real company compliance handbook*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a09fb24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cell 2: Create Sample English Data\n",
    "sample_english_content = \"\"\"\n",
    "GDPR COMPLIANCE HANDBOOK FOR SMALL BUSINESSES\n",
    "\n",
    "SECTION 1: BASIC PRINCIPLES\n",
    "\n",
    "Article 1: Data Protection Principles\n",
    "Personal data must be processed lawfully, fairly, and transparently. \n",
    "Businesses must clearly state why they collect data and how it will be used.\n",
    "\n",
    "Article 2: Lawful Basis for Processing\n",
    "You can process personal data when:\n",
    "- You have explicit consent from the individual\n",
    "- It's necessary for a contract\n",
    "- It's required by law\n",
    "- It's in the legitimate interests of your business\n",
    "\n",
    "Article 3: Data Minimization\n",
    "Only collect data that is strictly necessary for your specific purpose.\n",
    "Do not collect excessive or irrelevant information.\n",
    "\n",
    "SECTION 2: CUSTOMER DATA HANDLING\n",
    "\n",
    "Article 4: Customer Consent\n",
    "For marketing emails, you must have explicit opt-in consent.\n",
    "Pre-ticked boxes or assumed consent are not valid.\n",
    "Customers must be able to withdraw consent easily.\n",
    "\n",
    "Article 5: Data Retention\n",
    "Keep customer data only as long as necessary:\n",
    "- Invoices and contracts: 10 years\n",
    "- Marketing consent: 2 years (unless renewed)\n",
    "- Customer complaints: 6 years\n",
    "\n",
    "Article 6: Data Subject Rights\n",
    "Customers have the right to:\n",
    "- Access their personal data\n",
    "- Correct inaccurate data\n",
    "- Request deletion of their data\n",
    "- Object to data processing\n",
    "\n",
    "SECTION 3: EMPLOYEE DATA\n",
    "\n",
    "Article 7: Employee Records\n",
    "Keep employee data secure and confidential:\n",
    "- Employment contracts: 6 years after employment ends\n",
    "- Salary records: 10 years\n",
    "- Performance reviews: 3 years\n",
    "\n",
    "Article 8: Recruitment Data\n",
    "Unsuccessful applicant data: 6 months\n",
    "Interview notes: 12 months\n",
    "\n",
    "SECTION 4: DATA BREACH PROCEDURES\n",
    "\n",
    "Article 9: Breach Notification\n",
    "Report data breaches to authorities within 72 hours.\n",
    "Inform affected individuals if there is high risk to their rights.\n",
    "Document all breaches for internal records.\n",
    "\n",
    "Article 10: Security Measures\n",
    "Implement appropriate technical security measures.\n",
    "Train staff on data protection principles.\n",
    "Regularly review and update security practices.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54ccc308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Sample English handbook created!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Save sample data\n",
    "os.makedirs(\"../2_data/raw\", exist_ok=True)\n",
    "with open(\"../2_data/raw/sample_english_handbook.txt\", \"w\") as f:\n",
    "    f.write(sample_english_content)\n",
    "\n",
    "print(\"‚úÖ Sample English handbook created!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d5ff1b",
   "metadata": {},
   "source": [
    "## üîç Load & Explore Data\n",
    "\n",
    "*Load our sample data and examine its structure*\n",
    "\n",
    "**Key Questions**:\n",
    "- How much text do we have?\n",
    "- What's the content structure?\n",
    "- Are there clear sections we can use?\n",
    "\n",
    "*Understanding your data is crucial for good chunking strategy*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfefa024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Number of documents: 1\n",
      "üìù First 500 characters:\n",
      "\n",
      "GDPR COMPLIANCE HANDBOOK FOR SMALL BUSINESSES\n",
      "\n",
      "SECTION 1: BASIC PRINCIPLES\n",
      "\n",
      "Article 1: Data Protection Principles\n",
      "Personal data must be processed lawfully, fairly, and transparently. \n",
      "Businesses must clearly state why they collect data and how it will be used.\n",
      "\n",
      "Article 2: Lawful Basis for Processing\n",
      "You can process personal data when:\n",
      "- You have explicit consent from the individual\n",
      "- It's necessary for a contract\n",
      "- It's required by law\n",
      "- It's in the legitimate interests of your business\n",
      "\n",
      "Articl...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Cell 3: Load and Explore the Data\n",
    "loader = TextLoader(\"../2_data/raw/sample_english_handbook.txt\", encoding='utf-8')\n",
    "documents = loader.load()\n",
    "\n",
    "print(f\"üìÑ Number of documents: {len(documents)}\")\n",
    "print(f\"üìù First 500 characters:\")\n",
    "print(documents[0].page_content[:500] + \"...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997baee0",
   "metadata": {},
   "source": [
    "## ‚úÇÔ∏è Text Chunking\n",
    "\n",
    "*Split the document into smaller pieces for processing*\n",
    "\n",
    "**Why chunking matters**:\n",
    "- LLMs have context window limits\n",
    "- Smaller chunks are easier to search\n",
    "- Better precision in retrieval\n",
    "\n",
    "**Parameters we're using**:\n",
    "- `chunk_size=500`: Balance between context and precision\n",
    "- `chunk_overlap=50`: Maintain context between chunks\n",
    "- Smart separators: Prefer natural breaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "604a8f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÇÔ∏è Created 5 text chunks\n",
      "\n",
      "üìã Sample chunk:\n",
      "Content: Article 5: Data Retention\n",
      "Keep customer data only as long as necessary:\n",
      "- Invoices and contracts: 10 years\n",
      "- Marketing consent: 2 years (unless renewed)\n",
      "- Customer complaints: 6 years\n",
      "\n",
      "Article 6: Data...\n",
      "Length: 386 characters\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Split Text into Chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=50,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \". \", \"! \", \"? \", \" \", \"\"]\n",
    ")\n",
    "\n",
    "en_sample_chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "print(f\"‚úÇÔ∏è Created {len(en_sample_chunks)} text chunks\")\n",
    "print(\"\\nüìã Sample chunk:\")\n",
    "print(f\"Content: {en_sample_chunks[2].page_content[:200]}...\")\n",
    "print(f\"Length: {len(en_sample_chunks[2].page_content)} characters\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc86f42f",
   "metadata": {},
   "source": [
    "## üìä Chunk Analysis\n",
    "\n",
    "*Examine the results of our chunking strategy*\n",
    "\n",
    "**What to check**:\n",
    "- Number of chunks created\n",
    "- Size distribution\n",
    "- Content quality\n",
    "\n",
    "**Common Issues**:\n",
    "- ‚ùå Chunks too small (lose context)\n",
    "- ‚ùå Chunks too large (irrelevant info)\n",
    "- ‚úÖ Balanced chunks (optimal retrieval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df7afaea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Chunk statistics:\n",
      "Min length: 338\n",
      "Max length: 491\n",
      "Avg length: 399.2\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Examine Chunk Distribution\n",
    "chunk_lengths = [len(chunk.page_content) for chunk in en_sample_chunks]\n",
    "\n",
    "print(f\"üìä Chunk statistics:\")\n",
    "print(f\"Min length: {min(chunk_lengths)}\")\n",
    "print(f\"Max length: {max(chunk_lengths)}\")\n",
    "print(f\"Avg length: {sum(chunk_lengths)/len(chunk_lengths):.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23f49f2",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6003c135",
   "metadata": {},
   "source": [
    "## üá©üá™ German PDF Extraction\n",
    "\n",
    "*Now let's extract text from your actual German PDF*\n",
    "\n",
    "**What we'll do**:\n",
    "1. Check if German PDF exists\n",
    "2. Extract text automatically\n",
    "3. Process German text chunks\n",
    "4. Compare with English version\n",
    "\n",
    "**Important**: We'll use the same chunking strategy for both languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee9ee5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Extract Text from German PDF\n",
    "def extract_german_pdf(pdf_path):\n",
    "    \"\"\"Extract text from German PDF automatically\"\"\"\n",
    "    try:\n",
    "        print(f\"üîç Attempting to extract text from: {pdf_path}\")\n",
    "        \n",
    "        # Check if file exists\n",
    "        if not os.path.exists(pdf_path):\n",
    "            print(f\"‚ùå File not found: {pdf_path}\")\n",
    "            print(\"üí° Please place your German PDF in the data/raw/ folder\")\n",
    "            return None\n",
    "        \n",
    "        # Load PDF using PyPDFLoader\n",
    "        loader = PyPDFLoader(pdf_path)\n",
    "        german_documents = loader.load()\n",
    "        \n",
    "        print(f\"‚úÖ Successfully extracted {len(german_documents)} pages from German PDF\")\n",
    "        \n",
    "        # Show sample content from first page\n",
    "        if german_documents:\n",
    "            first_page_content = german_documents[0].page_content\n",
    "            print(f\"\\nüìÑ Sample from first page (first 300 characters):\")\n",
    "            print(first_page_content[:300] + \"...\" if len(first_page_content) > 300 else first_page_content)\n",
    "            \n",
    "            # Check if text looks like German\n",
    "            german_keywords = ['der', 'die', 'das', 'und', 'f√ºr', 'von', 'mit', 'Datenschutz', 'DSGVO']\n",
    "            found_keywords = [word for word in german_keywords if word in first_page_content]\n",
    "            print(f\"\\nüî§ German keywords found: {found_keywords}\")\n",
    "        \n",
    "        return german_documents\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error extracting PDF: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67f24dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Attempting to extract text from: ../2_data/raw/ZDH_LEITFADEN_DATENSCHUTZ_BETRIEBE_HANDWERKER.pdf\n",
      "‚úÖ Successfully extracted 99 pages from German PDF\n",
      "\n",
      "üìÑ Sample from first page (first 300 characters):\n",
      "Leitfaden \n",
      "Datenschutzrecht \n",
      "Was Betriebe zu beachten haben \n",
      " \n",
      " \n",
      "Stand: November 2020 \n",
      " \n",
      "Abteilung Organisation und Recht\n",
      "\n",
      "üî§ German keywords found: ['und', 'Datenschutz']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Try to extract German PDF\n",
    "german_pdf_path = \"../2_data/raw/ZDH_LEITFADEN_DATENSCHUTZ_BETRIEBE_HANDWERKER.pdf\"\n",
    "german_documents = extract_german_pdf(german_pdf_path)\n",
    "\n",
    "# If no German PDF found, create a sample German text for testing\n",
    "if german_documents is None:\n",
    "    print(\"\\nüìù Creating sample German text for testing...\")\n",
    "    \n",
    "    sample_german_content = \"\"\"\n",
    "    Datenschutz-Handbuch f√ºr Handwerksbetriebe\n",
    "    \n",
    "    Kapitel 1: Grundlagen der DSGVO\n",
    "    \n",
    "    Artikel 1: Datenschutzgrunds√§tze\n",
    "    Personenbezogene Daten m√ºssen rechtm√§√üig, nach Treu und Glauben und transparent verarbeitet werden.\n",
    "    Unternehmen m√ºssen klar angeben, warum sie Daten sammeln und wie sie verwendet werden.\n",
    "    \n",
    "    Artikel 2: Rechtsgrundlagen der Verarbeitung\n",
    "    Sie d√ºrfen personenbezogene Daten verarbeiten, wenn:\n",
    "    - Die betroffene Person eingewilligt hat\n",
    "    - Die Verarbeitung f√ºr einen Vertrag erforderlich ist\n",
    "    - Eine gesetzliche Verpflichtung besteht\n",
    "    - Berechtigte Interessen des Unternehmens vorliegen\n",
    "    \n",
    "    Artikel 3: Datenminimierung\n",
    "    Sammeln Sie nur Daten, die f√ºr den spezifischen Zweck unbedingt erforderlich sind.\n",
    "    Vermeiden Sie excessive oder irrelevante Informationen.\n",
    "    \n",
    "    Kapitel 2: Umgang mit Kundendaten\n",
    "    \n",
    "    Artikel 4: Kunden Einwilligung\n",
    "    F√ºr Marketing-E-Mails ist eine ausdr√ºckliche Opt-In-Einwilligung erforderlich.\n",
    "    Vorangekreuzte K√§stchen oder stillschweigende Zustimmung sind nicht g√ºltig.\n",
    "    Kunden m√ºssen ihre Einwilligung jederzeit widerrufen k√∂nnen.\n",
    "    \n",
    "    Artikel 5: Aufbewahrungsfristen\n",
    "    Bewahren Sie Kundendaten nur so lange auf wie n√∂tig:\n",
    "    - Rechnungen und Vertr√§ge: 10 Jahre\n",
    "    - Marketing-Einwilligungen: 2 Jahre (sofern nicht erneuert)\n",
    "    - Kundenbeschwerden: 6 Jahre\n",
    "    \"\"\"\n",
    "    \n",
    "    # Save sample German text\n",
    "    with open(\"../2_data/raw/sample_german_handbook.txt\", \"w\", encoding='utf-8') as f:\n",
    "        f.write(sample_german_content)\n",
    "    \n",
    "    # Load the sample German text\n",
    "    loader = TextLoader(\"../2_data/raw/sample_german_handbook.txt\", encoding='utf-8')\n",
    "    german_documents = loader.load()\n",
    "    \n",
    "    print(\"‚úÖ Sample German handbook created for testing!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33a4deeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üî® Processing German text chunks...\n",
      "‚úÇÔ∏è Created 379 German text chunks\n",
      "üìä German chunk sizes: [121, 471, 447]...\n",
      "\n",
      "üìã Sample German chunk:\n",
      "Content: Vorwort \n",
      "Seit dem 25. Mai 2018 gelten in allen Mitgliedstaaten der Europ√§ischen Union neue Daten-\n",
      "schutzregeln. Mit der Reform soll sichergestellt werden, dass in allen Mitgliedstaaten derselbe \n",
      "Daten...\n",
      "\n",
      "üìà Comparison:\n",
      "English chunks: 5\n",
      "German chunks: 379\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Process German Text Chunks\n",
    "if german_documents:\n",
    "    print(\"\\nüî® Processing German text chunks...\")\n",
    "    \n",
    "    # Use the same text splitter for consistency\n",
    "    german_chunks = text_splitter.split_documents(german_documents)\n",
    "    \n",
    "    print(f\"‚úÇÔ∏è Created {len(german_chunks)} German text chunks\")\n",
    "    print(f\"üìä German chunk sizes: {[len(chunk.page_content) for chunk in german_chunks[:3]]}...\")\n",
    "    \n",
    "    # Show sample German chunk\n",
    "    if german_chunks:\n",
    "        print(f\"\\nüìã Sample German chunk:\")\n",
    "        print(f\"Content: {german_chunks[1].page_content[:200]}...\")\n",
    "        \n",
    "    # Compare English vs German\n",
    "    print(f\"\\nüìà Comparison:\")\n",
    "    print(f\"English chunks: {len(en_sample_chunks)}\")\n",
    "    print(f\"German chunks: {len(german_chunks)}\")\n",
    "else:\n",
    "    print(\"‚ùå No German documents to process\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11a03eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'producer': 'Microsoft¬Æ Word f√ºr Office 365', 'creator': 'Microsoft¬Æ Word f√ºr Office 365', 'creationdate': '2020-11-06T11:24:59+01:00', 'author': 'Kasper, Lisa', 'moddate': '2020-11-06T11:24:59+01:00', 'source': '../2_data/raw/ZDH_LEITFADEN_DATENSCHUTZ_BETRIEBE_HANDWERKER.pdf', 'total_pages': 99, 'page': 98, 'page_label': '99'}\n",
      "Ort, Datum, Unterschrift \n",
      " \n",
      " \n",
      " \n",
      "Die Datenverarbeitung ist f√ºr die Kontaktaufnahme per Telefon, Fax und E -Mail erforderlich und be-\n",
      "ruht auf Artikel 6 Abs. 1 a) DSGVO. Eine Weitergabe der Daten an Dritte findet nicht statt. Die Daten \n",
      "werden gel√∂scht, sobald sie f√ºr den Zweck ihrer Verarbeitung nicht mehr erforderlich sind.  \n",
      " \n",
      "Sie sind berechtigt, Auskunft der bei uns √ºber Sie gespeicherten Daten zu beantragen sowie bei Un-\n"
     ]
    }
   ],
   "source": [
    "print(german_chunks[377].metadata)\n",
    "print(german_chunks[377].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b185776e",
   "metadata": {},
   "source": [
    "## üíæ Save Results\n",
    "\n",
    "*Save processed chunks for the next notebook*\n",
    "\n",
    "**What we're saving**:\n",
    "- English text chunks with metadata\n",
    "- German text chunks with metadata  \n",
    "- Ready for embedding generation\n",
    "\n",
    "**Next Steps**:\n",
    "- Vector database setup in Notebook 2\n",
    "- Multilingual embedding generation\n",
    "- Cross-language search testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9aad7496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All text chunks saved for next notebook!\n",
      "üìÅ English chunks: 5\n",
      "üìÅ German chunks: 379\n",
      "\n",
      "üéâ Ready for Notebook 2: Vector Database Setup!\n",
      "‚û°Ô∏è Next: We'll create embeddings and set up semantic search for both languages\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Save All Chunks for Next Notebook\n",
    "\n",
    "# Combine or save separately based on your needs\n",
    "all_chunks = {\n",
    "    'english': en_sample_chunks,\n",
    "    'german': german_chunks if 'german_chunks' in locals() else []\n",
    "}\n",
    "\n",
    "os.makedirs(\"../2_data/processed\", exist_ok=True)\n",
    "with open(\"../2_data/processed/text_chunks.pkl\", \"wb\") as f:\n",
    "    pickle.dump(all_chunks, f)\n",
    "\n",
    "print(\"‚úÖ All text chunks saved for next notebook!\")\n",
    "print(f\"üìÅ English chunks: {len(en_sample_chunks)}\")\n",
    "if 'german_chunks' in locals():\n",
    "    print(f\"üìÅ German chunks: {len(german_chunks)}\")\n",
    "\n",
    "print(\"\\nüéâ Ready for Notebook 2: Vector Database Setup!\")\n",
    "print(\"‚û°Ô∏è Next: We'll create embeddings and set up semantic search for both languages\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cddba68a",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "-----"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LangChain",
   "language": "python",
   "name": "langchain_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
